{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>DTSC 5502.022 - Principles and Techniques of Data Science, Data Science Master Program, Dept. of Data Science, University of North Texas, Denton, TX</center>\n",
    "\n",
    "# <center>Machine Learning Modeling Building, Evaluation and Parameter Tuning</center> \n",
    "\n",
    "<center>Invited Lecture - Bishnu Sarker, Assitant Professor of Health Informatics, Dept. of Information Science, University of North Texas, Denton TX</center> \n",
    "<center> bishnu.sarker@unt.edu || Office: DP E295P || Hours: Monday-Tuesday; 3:00-5:00PM </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Module Description:**\n",
    "This module provides a comprehensive overview of the entire modeling lifecycle, from model selection to performance evaluation. \n",
    "Students will learn :\n",
    "1. how to choose appropriate models for different types of problems \n",
    "2. will gain essential skills in evaluating their effectiveness using a variety of metrics.\n",
    "3. Will understand  techniques such as cross-validation and hyperparameter tuning to ensure that models are both robust and accurate.\n",
    "4. adiitionally, they will learn to build apps to deploy the model. \n",
    "\n",
    "**Learning Outcomes**\n",
    "By the end of this task, students will:\n",
    "1. Understand the end-to-end workflow for building a classification model\n",
    "2. Evaluate models using multiple metrics\n",
    "3. Tune hyper parameters. \n",
    "4. Make informed decisions for model selection\n",
    "\n",
    "**Machine Learning Life Cycle** \n",
    "\n",
    "0. Problem Statement\n",
    "1. Data collection, preprocessing and normalization, feature selection and data matrix structuring.\n",
    "2. Preparing training dataset, validation dataset and testing dataset\n",
    "3. Training machine learning models on the training data, tuning on validation data, and  evaluating on testing data. \n",
    "4. Repeating step 3 on multiple machine learning algorithms and tracking and recording the evaluation metrics. \n",
    "5. Model selection based on the performance criteria. \n",
    "6. Building apps and deploying the best model and continous monitoring for drifting.\n",
    "7. Repeating the 1-6 if model fails to serve the purpose in the future.  \n",
    "\n",
    "**Agenda**\n",
    "\n",
    "1. Introduction to the machine learning - a refresher\n",
    "2. Building a Machine Learning Pipeline - Basic model building to cross-validation and parameter tuning. \n",
    "3. Building a Streamlit App to deploying the model. \n",
    "4. Discussing my research and opportunities. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Problem Statement\n",
    "\n",
    "The very first step is to define the machine learning task. \n",
    "\n",
    "In this practice note, our objective of the machine learning task is  predicting if a patient has diabetics or not from several of features given in the dataset. We will be working on PIMA INDIANS DIABETES DATA to predict the Onset of diabetes based on diagnostic measurements. \n",
    "The data and problem is defined here: https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database \n",
    "\n",
    "Also, a direct access to data exists through: \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\" \n",
    "\n",
    "The following description of the attributes of the data is taken from: https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\n",
    "\n",
    "Here is the list of attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)     --- target variable/response variable/ depedant variable/ labels/class\n",
    "   \n",
    "   \n",
    " The data was part of the following publication:\n",
    " \n",
    " Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications and Medical Care (pp. 261--265). IEEE Computer Society Press.\n",
    " \n",
    "The Proposed ADAP algorithm used 576 instances for training and recorded the sensitivity and specificity\n",
    "       of their algorithm was 76% on the remaining 192 instances as test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Step: Setting up the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download and Install Python**\n",
    "\n",
    "You should be having a working python environment from your past working experience.  If you don't have a working python environment, please go to Anaconda webpage and download latest anaconda distribution for your os.  https://www.anaconda.com/download "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding how to work with Numpy, Scipy, matplotlib and Pandas**\n",
    "\n",
    "I expect you to have working knowledge of numpy, scipy, matplotlib and pandas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the packages**\n",
    "\n",
    "Most cases, you will need the following packages to work with machine learning project in Python. \n",
    "1. Pandas \n",
    "2. Matplotlib\n",
    "3. Numpy\n",
    "4. Scipy\n",
    "5. Sklearn\n",
    "\n",
    "Let's import the above packages and also check if the system is ready for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T22:59:58.076788Z",
     "iopub.status.busy": "2024-10-16T22:59:58.075816Z",
     "iopub.status.idle": "2024-10-16T22:59:58.487041Z",
     "shell.execute_reply": "2024-10-16T22:59:58.485745Z",
     "shell.execute_reply.started": "2024-10-16T22:59:58.076746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data collection, preprocessing and normalization, feature selection and data matrix structuring.\n",
    "Let's use Pandas to read the data from the online source and get it into a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:00:23.187326Z",
     "iopub.status.busy": "2024-10-16T23:00:23.186780Z",
     "iopub.status.idle": "2024-10-16T23:00:23.398134Z",
     "shell.execute_reply": "2024-10-16T23:00:23.396961Z",
     "shell.execute_reply.started": "2024-10-16T23:00:23.187292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_src=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"   # data source\n",
    "features=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']   # column names\n",
    "data=pd.read_csv(data_src, names=features)    # pandas function for reading CSV file\n",
    "print(data.shape)  # prints the shape of the dataframe. number of rows, number of columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that there are 768 instances/examples/observations/rows  and 9 features/attributes/columns/fields in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:01:21.321092Z",
     "iopub.status.busy": "2024-10-16T23:01:21.320090Z",
     "iopub.status.idle": "2024-10-16T23:01:21.335259Z",
     "shell.execute_reply": "2024-10-16T23:01:21.334077Z",
     "shell.execute_reply.started": "2024-10-16T23:01:21.321055Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# First few rows of the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:01:24.033186Z",
     "iopub.status.busy": "2024-10-16T23:01:24.032782Z",
     "iopub.status.idle": "2024-10-16T23:01:24.046802Z",
     "shell.execute_reply": "2024-10-16T23:01:24.045640Z",
     "shell.execute_reply.started": "2024-10-16T23:01:24.033151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Last few rows of the data\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Analysis**\n",
    "\n",
    "It is always a good idea to look at the summary of the dataset. This first step often helps with feature engineering for example finding right features for the model. In other words, identifying the right set of columns that are explanatory of the target variable. \n",
    "\n",
    "Let us look into the statistical description of the data. This gives the basics statistical measure of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:01:27.317894Z",
     "iopub.status.busy": "2024-10-16T23:01:27.316908Z",
     "iopub.status.idle": "2024-10-16T23:01:27.356951Z",
     "shell.execute_reply": "2024-10-16T23:01:27.355915Z",
     "shell.execute_reply.started": "2024-10-16T23:01:27.317856Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to know the data type of the features/columns is to use info() function. This gives the total row/column number as well type of each columns including if there is any null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:01:38.770404Z",
     "iopub.status.busy": "2024-10-16T23:01:38.770008Z",
     "iopub.status.idle": "2024-10-16T23:01:38.797457Z",
     "shell.execute_reply": "2024-10-16T23:01:38.796212Z",
     "shell.execute_reply.started": "2024-10-16T23:01:38.770371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:01:55.996932Z",
     "iopub.status.busy": "2024-10-16T23:01:55.996536Z",
     "iopub.status.idle": "2024-10-16T23:01:57.111171Z",
     "shell.execute_reply": "2024-10-16T23:01:57.110020Z",
     "shell.execute_reply.started": "2024-10-16T23:01:55.996898Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is matrix of box plots. each sub plot is a box plot for of column\n",
    "data.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot is a nice way to locate outliers. Above charts show that there are many points which are out of accepted range of boxplots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:02:21.125050Z",
     "iopub.status.busy": "2024-10-16T23:02:21.124059Z",
     "iopub.status.idle": "2024-10-16T23:02:22.503023Z",
     "shell.execute_reply": "2024-10-16T23:02:22.501933Z",
     "shell.execute_reply.started": "2024-10-16T23:02:21.125011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Histogram of each column\n",
    "data.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many features which seems to be not normally distributed. This is an important insight because many machine learning learning models assume data to be normally distributed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now count how many different classes do we have in the dataset.  groupby() is a easy way to get it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:02:52.408901Z",
     "iopub.status.busy": "2024-10-16T23:02:52.408217Z",
     "iopub.status.idle": "2024-10-16T23:02:52.419397Z",
     "shell.execute_reply": "2024-10-16T23:02:52.418234Z",
     "shell.execute_reply.started": "2024-10-16T23:02:52.408860Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# to look at class wise counts of rows\n",
    "data.groupby(\"class\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result shows that there are two classes: 0 and 1. For 0, there are 500 instances, for 1, there are 268 instances. This data set is class imbalance as the number of instances between 2 classes vary significantly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:04:06.046314Z",
     "iopub.status.busy": "2024-10-16T23:04:06.045778Z",
     "iopub.status.idle": "2024-10-16T23:04:06.052195Z",
     "shell.execute_reply": "2024-10-16T23:04:06.050747Z",
     "shell.execute_reply.started": "2024-10-16T23:04:06.046277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is correlation matrix between the columns\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:04:09.792621Z",
     "iopub.status.busy": "2024-10-16T23:04:09.791644Z",
     "iopub.status.idle": "2024-10-16T23:04:14.255932Z",
     "shell.execute_reply": "2024-10-16T23:04:14.254876Z",
     "shell.execute_reply.started": "2024-10-16T23:04:09.792583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "scatter_matrix(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scatter plot is a nice way to plot the co-relation among features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing/Standardization of data**\n",
    "\n",
    "Often times, the features present different measurements. It is important that we normalize the data before moving to model development. Normalization converts any data point to a uniform units. There are many normalization techniques based on the assumption of the data distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:04:29.746356Z",
     "iopub.status.busy": "2024-10-16T23:04:29.745949Z",
     "iopub.status.idle": "2024-10-16T23:04:29.751847Z",
     "shell.execute_reply": "2024-10-16T23:04:29.750601Z",
     "shell.execute_reply.started": "2024-10-16T23:04:29.746323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## From dataframe values to numpy arrays. While you can still do everything on Dataframes. Following example will show how to \n",
    "## use numpy in the process. \n",
    "data_array=data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:04:32.808902Z",
     "iopub.status.busy": "2024-10-16T23:04:32.807752Z",
     "iopub.status.idle": "2024-10-16T23:04:32.815293Z",
     "shell.execute_reply": "2024-10-16T23:04:32.814130Z",
     "shell.execute_reply.started": "2024-10-16T23:04:32.808859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Again to look at the shape of the array\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:04:40.248232Z",
     "iopub.status.busy": "2024-10-16T23:04:40.247792Z",
     "iopub.status.idle": "2024-10-16T23:04:40.256506Z",
     "shell.execute_reply": "2024-10-16T23:04:40.255127Z",
     "shell.execute_reply.started": "2024-10-16T23:04:40.248196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the last column of the dataframe was the label column. That means, the task of the model would be to predict the values of the last column given the values of the other columns i.e. features. \n",
    "lets seperate these two parts into two variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:05:09.819241Z",
     "iopub.status.busy": "2024-10-16T23:05:09.818761Z",
     "iopub.status.idle": "2024-10-16T23:05:09.825393Z",
     "shell.execute_reply": "2024-10-16T23:05:09.824030Z",
     "shell.execute_reply.started": "2024-10-16T23:05:09.819203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Seperating the feature columns and label column. In this example, the last column is the label column. \n",
    "X=data_array[:, 0:8]\n",
    "Y=data_array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:05:12.112607Z",
     "iopub.status.busy": "2024-10-16T23:05:12.111754Z",
     "iopub.status.idle": "2024-10-16T23:05:12.119891Z",
     "shell.execute_reply": "2024-10-16T23:05:12.118726Z",
     "shell.execute_reply.started": "2024-10-16T23:05:12.112566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## this is the feature matrix\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:05:15.720870Z",
     "iopub.status.busy": "2024-10-16T23:05:15.720151Z",
     "iopub.status.idle": "2024-10-16T23:05:15.732658Z",
     "shell.execute_reply": "2024-10-16T23:05:15.731547Z",
     "shell.execute_reply.started": "2024-10-16T23:05:15.720832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# this is list of labels\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets apply the normalization function. Following normalization assumes that the data is normally distributed. thus it computes the Z-score against each value in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:06:19.489424Z",
     "iopub.status.busy": "2024-10-16T23:06:19.488959Z",
     "iopub.status.idle": "2024-10-16T23:06:20.204396Z",
     "shell.execute_reply": "2024-10-16T23:06:20.203203Z",
     "shell.execute_reply.started": "2024-10-16T23:06:19.489389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# FFunction for normalizing the numerical values. Z=(X-mean)/SD \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:06:24.940111Z",
     "iopub.status.busy": "2024-10-16T23:06:24.939624Z",
     "iopub.status.idle": "2024-10-16T23:06:24.947554Z",
     "shell.execute_reply": "2024-10-16T23:06:24.946404Z",
     "shell.execute_reply.started": "2024-10-16T23:06:24.940075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rescaledX=StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:06:27.746671Z",
     "iopub.status.busy": "2024-10-16T23:06:27.746162Z",
     "iopub.status.idle": "2024-10-16T23:06:27.755474Z",
     "shell.execute_reply": "2024-10-16T23:06:27.754297Z",
     "shell.execute_reply.started": "2024-10-16T23:06:27.746631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rescaledX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rescaledX holds the scaled/normalized/standarized data points of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have prepared your data matrix, the next thing is to fit a machine learning model. There are few steps: spliting the data into train and test set; fitting the model in training set; evaluating the model on test set; displaying the performance metrics to know the model strength. \n",
    "\n",
    "### 2. Preparing training dataset, validation dataset and testing dataset\n",
    "\n",
    "At this point, we know how to read data and pre-process data to re-scale ot nirmalize data. Now, we will see how to apply a machine learning model using SKLEARN package. \n",
    "In this step, we need some special libraries to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:08:33.584275Z",
     "iopub.status.busy": "2024-10-16T23:08:33.583752Z",
     "iopub.status.idle": "2024-10-16T23:08:33.996322Z",
     "shell.execute_reply": "2024-10-16T23:08:33.995213Z",
     "shell.execute_reply.started": "2024-10-16T23:08:33.584237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Import the following packages for any machine learning project. \n",
    "# Preparing the dataset\n",
    "from sklearn.model_selection import train_test_split   # split the dataset into training and testing set\n",
    "from sklearn.model_selection import cross_val_score    # Perform cross validation \n",
    "from sklearn.model_selection import StratifiedKFold    # Stratify the data in each fold\n",
    "from sklearn.model_selection import KFold              # Defining the number of fold in Cross-validation\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import classification_report     # to get the performance measures\n",
    "from sklearn.metrics import confusion_matrix          # To compute the false positives and false negatives\n",
    "from sklearn.metrics import accuracy_score            # Accuracy measures\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression   # Logistics Regression Model\n",
    "from sklearn.tree import DecisionTreeClassifier       # Decision Tree Model\n",
    "from sklearn.neighbors import KNeighborsClassifier    # K-nearest Neighbor model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis   #LDA model\n",
    "from sklearn.naive_bayes import GaussianNB                             # naive Bayes\n",
    "from sklearn.svm import SVC                                            # Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Essentially, following line split the rescaledX and Y into four new variables. \n",
    "\n",
    "- X_train: the feauture matrix for training\n",
    "- X_test: the feature matrix for training\n",
    "- Y_train: label vector for training\n",
    "- Y_test: label vector for testing - also known as ground truth labels. \n",
    "\n",
    "test_size=0.2 will ensure that 80% of the rescaledX goes to training and 20% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:08:40.582539Z",
     "iopub.status.busy": "2024-10-16T23:08:40.582137Z",
     "iopub.status.idle": "2024-10-16T23:08:40.589137Z",
     "shell.execute_reply": "2024-10-16T23:08:40.587893Z",
     "shell.execute_reply.started": "2024-10-16T23:08:40.582507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(rescaledX, Y, test_size=0.2) # Adhering to 80:20 rule for train:test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:16:57.887540Z",
     "iopub.status.busy": "2024-10-16T23:16:57.887131Z",
     "iopub.status.idle": "2024-10-16T23:16:57.895335Z",
     "shell.execute_reply": "2024-10-16T23:16:57.894126Z",
     "shell.execute_reply.started": "2024-10-16T23:16:57.887508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Training machine learning models on the training data, tuning on validation data, and  evaluating on testing data. \n",
    "Now we are going to use X_train and Y_train as our primary data for building the model. Once the model is build, we will use X_train and Y_Train to validate the performance of the model. \n",
    "\n",
    "Following 2 lines of code actually build a model around train data: X_train and Y_train. \n",
    "\n",
    "**Training Machine Learning Models: Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:14:48.795302Z",
     "iopub.status.busy": "2024-10-16T23:14:48.794873Z",
     "iopub.status.idle": "2024-10-16T23:14:48.805217Z",
     "shell.execute_reply": "2024-10-16T23:14:48.803862Z",
     "shell.execute_reply.started": "2024-10-16T23:14:48.795271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:10:16.033715Z",
     "iopub.status.busy": "2024-10-16T23:10:16.033200Z",
     "iopub.status.idle": "2024-10-16T23:10:16.052457Z",
     "shell.execute_reply": "2024-10-16T23:10:16.051260Z",
     "shell.execute_reply.started": "2024-10-16T23:10:16.033677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "LR=LogisticRegression(solver='liblinear', max_iter=200, penalty='l1')\n",
    "#fit(X_train, Y_train) \n",
    "LR.fit(X_train, Y_train) \n",
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testign a ML model**\n",
    "\n",
    "Once the model is trained, following one line can be used to predict the classes for test set. X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:11:37.110511Z",
     "iopub.status.busy": "2024-10-16T23:11:37.109699Z",
     "iopub.status.idle": "2024-10-16T23:11:37.118048Z",
     "shell.execute_reply": "2024-10-16T23:11:37.116938Z",
     "shell.execute_reply.started": "2024-10-16T23:11:37.110473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On a single data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:13:42.267246Z",
     "iopub.status.busy": "2024-10-16T23:13:42.266806Z",
     "iopub.status.idle": "2024-10-16T23:13:42.274787Z",
     "shell.execute_reply": "2024-10-16T23:13:42.273616Z",
     "shell.execute_reply.started": "2024-10-16T23:13:42.267212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x1=X_test[1]\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:13:47.084603Z",
     "iopub.status.busy": "2024-10-16T23:13:47.083594Z",
     "iopub.status.idle": "2024-10-16T23:13:47.092114Z",
     "shell.execute_reply": "2024-10-16T23:13:47.091028Z",
     "shell.execute_reply.started": "2024-10-16T23:13:47.084555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_pred=LR.predict([x1])\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:18:47.179422Z",
     "iopub.status.busy": "2024-10-16T23:18:47.178903Z",
     "iopub.status.idle": "2024-10-16T23:18:47.189711Z",
     "shell.execute_reply": "2024-10-16T23:18:47.188276Z",
     "shell.execute_reply.started": "2024-10-16T23:18:47.179375Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "LR.predict_proba([x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:19:42.213800Z",
     "iopub.status.busy": "2024-10-16T23:19:42.213367Z",
     "iopub.status.idle": "2024-10-16T23:19:42.221786Z",
     "shell.execute_reply": "2024-10-16T23:19:42.220783Z",
     "shell.execute_reply.started": "2024-10-16T23:19:42.213744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "LR.predict_log_proba([x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:13:52.265988Z",
     "iopub.status.busy": "2024-10-16T23:13:52.264868Z",
     "iopub.status.idle": "2024-10-16T23:13:52.272580Z",
     "shell.execute_reply": "2024-10-16T23:13:52.271426Z",
     "shell.execute_reply.started": "2024-10-16T23:13:52.265926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On the entire test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:21:08.050286Z",
     "iopub.status.busy": "2024-10-16T23:21:08.049823Z",
     "iopub.status.idle": "2024-10-16T23:21:08.056244Z",
     "shell.execute_reply": "2024-10-16T23:21:08.054958Z",
     "shell.execute_reply.started": "2024-10-16T23:21:08.050254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_pred=LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:21:15.870555Z",
     "iopub.status.busy": "2024-10-16T23:21:15.870149Z",
     "iopub.status.idle": "2024-10-16T23:21:15.879106Z",
     "shell.execute_reply": "2024-10-16T23:21:15.878029Z",
     "shell.execute_reply.started": "2024-10-16T23:21:15.870520Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:21:28.134644Z",
     "iopub.status.busy": "2024-10-16T23:21:28.134224Z",
     "iopub.status.idle": "2024-10-16T23:21:28.142722Z",
     "shell.execute_reply": "2024-10-16T23:21:28.141495Z",
     "shell.execute_reply.started": "2024-10-16T23:21:28.134611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Performance: confusion Matrix**\n",
    "\n",
    "\n",
    "**Definition:** A confusion matrix is a table that summarizes the performance of a classification model by comparing **actual vs predicted labels**. It helps compute precision, recall, F1-score, accuracy, and other metrics.\n",
    "\n",
    "* **Structure (Binary Classification):**\n",
    "\n",
    "| Actual \\ Predicted  | Predicted Positive  | Predicted Negative  |\n",
    "| ------------------- | ------------------- | ------------------- |\n",
    "| **Actual Positive** | True Positive (TP)  | False Negative (FN) |\n",
    "| **Actual Negative** | False Positive (FP) | True Negative (TN)  |\n",
    "\n",
    "* **Interpretation:**\n",
    "\n",
    "  * **TP:** Correctly predicted positive\n",
    "  * **TN:** Correctly predicted negative\n",
    "  * **FP:** Incorrectly predicted positive (false alarm)\n",
    "  * **FN:** Incorrectly predicted negative (missed positive)\n",
    "\n",
    "* **Example:**\n",
    "  Suppose a medical test predicts disease presence for 100 patients:\n",
    "\n",
    "* TP = 40 (correctly detected disease)\n",
    "\n",
    "* TN = 45 (correctly identified healthy)\n",
    "\n",
    "* FP = 10 (healthy predicted as sick)\n",
    "\n",
    "* FN = 5 (sick predicted as healthy)\n",
    "\n",
    "**Confusion Matrix Table:**\n",
    "\n",
    "| Actual \\ Predicted | Positive | Negative |\n",
    "| ------------------ | -------- | -------- |\n",
    "| Positive           | 40       | 5        |\n",
    "| Negative           | 10       | 45       |\n",
    "\n",
    "\n",
    "\n",
    "The better understand model performance, we can use following line with Y_pred : predicted classes and Y_test : actual classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:22:29.557062Z",
     "iopub.status.busy": "2024-10-16T23:22:29.556573Z",
     "iopub.status.idle": "2024-10-16T23:22:29.567778Z",
     "shell.execute_reply": "2024-10-16T23:22:29.566387Z",
     "shell.execute_reply.started": "2024-10-16T23:22:29.557029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Performance: Classification Report**\n",
    "\n",
    "it provides a set of metrics to better evaluate the model's performance:  Following portion is formatted by using ChatGPT. \n",
    "\n",
    "**1. Precision**\n",
    "\n",
    "* **Definition:** Precision measures the proportion of positive predictions that are actually correct. It focuses on how many predicted positives are true positives.\n",
    "\n",
    "* **Formula:**\n",
    "  \n",
    "  [$\\text{Precision} = \\frac{TP}{TP + FP}$]\n",
    "  \n",
    "  where:\n",
    "  TP = True Positives, FP = False Positives\n",
    "\n",
    "* **Example:**\n",
    "  Suppose a model predicts 50 patients as having a disease:\n",
    "\n",
    "* 40 truly have the disease (TP = 40)\n",
    "\n",
    "* 10 do not (FP = 10)\n",
    "\n",
    "[\n",
    "$\\text{Precision} = \\frac{40}{40 + 10} = \\frac{40}{50} = 0.8$\n",
    "]\n",
    "**Interpretation:** 80% of predicted positives are correct.\n",
    "\n",
    "\n",
    "**2. Recall (Sensitivity / True Positive Rate)**\n",
    "\n",
    "* **Definition:** Recall measures the proportion of actual positives that are correctly identified. It focuses on how many true positives are captured.\n",
    "\n",
    "* **Formula:**\n",
    "  [\n",
    "  $\\text{Recall} = \\frac{TP}{TP + FN}$\n",
    "  ]\n",
    "  where FN = False Negatives\n",
    "\n",
    "* **Example:**\n",
    "  Suppose there are 50 actual patients with the disease:\n",
    "\n",
    "* The model correctly predicts 40 as positive (TP = 40)\n",
    "\n",
    "* Misses 10 (FN = 10)\n",
    "\n",
    "[\n",
    "$\\text{Recall} = \\frac{40}{40 + 10} = \\frac{40}{50} = 0.8$\n",
    "]\n",
    "**Interpretation:** The model identifies 80% of actual positive cases.\n",
    "\n",
    "\n",
    "**3. F1-Score**\n",
    "\n",
    "* **Definition:** F1-score is the harmonic mean of precision and recall. It balances the two metrics and is useful when both false positives and false negatives matter.\n",
    "\n",
    "* **Formula:**\n",
    "  [\n",
    "  $F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "  ]\n",
    "\n",
    "* **Example:**\n",
    "  Using the previous example:\n",
    "\n",
    "* Precision = 0.8, Recall = 0.8\n",
    "\n",
    "[\n",
    "$F1 = 2 \\times \\frac{0.8 \\times 0.8}{0.8 + 0.8} = 0.8$\n",
    "]\n",
    "**Interpretation:** Good balance between precision and recall.\n",
    "\n",
    "\n",
    "**4. Accuracy**\n",
    "\n",
    "* **Definition:** Accuracy measures the proportion of total predictions (both positive and negative) that are correct.\n",
    "\n",
    "* **Formula:**\n",
    "  [\n",
    "  $\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "  ]\n",
    "\n",
    "* **Example:**\n",
    "  Suppose we have:\n",
    "\n",
    "* TP = 40, TN = 45, FP = 10, FN = 5\n",
    "\n",
    "[\n",
    "$\\text{Accuracy} = \\frac{40 + 45}{40 + 45 + 10 + 5} = \\frac{85}{100} = 0.85$\n",
    "]\n",
    "**Interpretation:** 85% of all predictions are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:22:53.147096Z",
     "iopub.status.busy": "2024-10-16T23:22:53.146681Z",
     "iopub.status.idle": "2024-10-16T23:22:53.163790Z",
     "shell.execute_reply": "2024-10-16T23:22:53.162372Z",
     "shell.execute_reply.started": "2024-10-16T23:22:53.147066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T01:01:24.071167Z",
     "iopub.status.busy": "2023-09-07T01:01:24.070470Z",
     "iopub.status.idle": "2023-09-07T01:01:24.083289Z",
     "shell.execute_reply": "2023-09-07T01:01:24.082276Z",
     "shell.execute_reply.started": "2023-09-07T01:01:24.071113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance: Area under the curve (AUC) and Precision Recall Curves to explore for more robust evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary table of popular metrics to help:\n",
    "\n",
    "| Metric                     | Definition                                           | Formula                            | Example                                          |\n",
    "| -------------------------- | ---------------------------------------------------- | ---------------------------------- | ------------------------------------------------ |\n",
    "| **Precision**              | Correctness of positive predictions                  | $TP / (TP + FP) $                    | TP=40, FP=10 → 0.8                               |\n",
    "| **Recall**                 | Coverage of actual positives                         | $TP / (TP + FN) $                    | TP=40, FN=10 → 0.8                               |\n",
    "| **F1-Score**               | Harmonic mean of precision & recall                  | $2 * (P*R)/(P+R)  $                  | P=0.8, R=0.8 → 0.8                               |\n",
    "| **Accuracy**               | Overall correct predictions                          | $(TP + TN)/(TP + TN + FP + FN) $     | TP=40, TN=45, FP=10, FN=5 → 0.85                 |\n",
    "| **ROC Curve**              | TPR vs FPR at different thresholds                   | $TPR = TP/(TP+FN), FPR = FP/(FP+TN)$ | Plot TPR vs FPR                                  |\n",
    "| **AUC**                    | Area under ROC curve                                 | $∫ TPR(FPR) d(FPR)   $               | AUC=0.95 indicates excellent model               |\n",
    "| **Precision-Recall Curve** | Trade-off between precision and recall at thresholds | Vary threshold, plot P vs R        | PR curve shows how precision changes with recall |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Repeating step 3 on multiple machine learning algorithms and tracking and recording the evaluation metrics. \n",
    "\n",
    "**Repeating training, test steps for Decision Tree**\n",
    "\n",
    "Decision Tree is popular machine learning model that works by generating if-then-else rules from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:25:19.700838Z",
     "iopub.status.busy": "2024-10-16T23:25:19.700396Z",
     "iopub.status.idle": "2024-10-16T23:25:19.724582Z",
     "shell.execute_reply": "2024-10-16T23:25:19.723239Z",
     "shell.execute_reply.started": "2024-10-16T23:25:19.700808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DT=DecisionTreeClassifier() \n",
    "DT.fit(X_train, Y_train)\n",
    "Y_pred=DT.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeating training, test steps for Random Forest**\n",
    "\n",
    "Apply random forest machine learning model in a similar fashion. and compare the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeating training, test steps for Model X** \n",
    "Apply another Machine learning Model of your choice and compare the perfomance here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Validation and Evaluation**\n",
    "\n",
    "There are many ways to validate the performance of a model. Such as Cross-Validation. In cross-validation, the training data X_train will be splitted into K-folds - k number of chunks. Each model will be trained by taking 1 fold as validation set and rest of the k-1 folds combined to form training data. The average of the performances from K number of models will indicate the overall performances of the selected model. \n",
    "\n",
    "Cross-validation prevents the model overfitting as the model sees every instance for once as training and testing set. \n",
    "\n",
    "#### Cross-validation\n",
    "To perform cross validation, following steps are necessary:\n",
    "\n",
    "- defining the K-folds using KFold(): its takes number of folds, if data would be shufled. \n",
    "- Definig a model object. \n",
    "- Applying cross validation using cross_val_score() : it takes model, features, labels and kfolds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:29:37.880749Z",
     "iopub.status.busy": "2024-10-16T23:29:37.879778Z",
     "iopub.status.idle": "2024-10-16T23:29:37.921169Z",
     "shell.execute_reply": "2024-10-16T23:29:37.919984Z",
     "shell.execute_reply.started": "2024-10-16T23:29:37.880702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "results = cross_val_score(LR, rescaledX,Y, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:31:10.766948Z",
     "iopub.status.busy": "2024-10-16T23:31:10.766464Z",
     "iopub.status.idle": "2024-10-16T23:31:10.774904Z",
     "shell.execute_reply": "2024-10-16T23:31:10.773537Z",
     "shell.execute_reply.started": "2024-10-16T23:31:10.766906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the results prints a list of 10 numbers. These are basically accuracies from 10 different runs with 10 folds. \n",
    "\n",
    "We can just look into mean performance using following lines of codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:31:12.875287Z",
     "iopub.status.busy": "2024-10-16T23:31:12.874441Z",
     "iopub.status.idle": "2024-10-16T23:31:12.881660Z",
     "shell.execute_reply": "2024-10-16T23:31:12.880334Z",
     "shell.execute_reply.started": "2024-10-16T23:31:12.875244Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of the result: The model may perform with an accuracy of 77.216% with an deviation +/- 4.76%. Out of 100 test examples feed to the model, roughly 72 - 82 examples will be correctly classified. There is 23% chance of miss-classification.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model selection based on the performance criteria\n",
    "\n",
    "Sometimes, to justify the superiority of a model, we need to compare with other models.\n",
    "\n",
    "Following lines of code, 1) defines multiple machine learning models, apply cross validation on each of them, and present the mean performance for each.\n",
    "\n",
    "As well as, it draws a set of box plots shows the performance deviations among the models and withing the k-folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:33:12.719533Z",
     "iopub.status.busy": "2024-10-16T23:33:12.719130Z",
     "iopub.status.idle": "2024-10-16T23:33:13.497477Z",
     "shell.execute_reply": "2024-10-16T23:33:13.496461Z",
     "shell.execute_reply.started": "2024-10-16T23:33:12.719499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "# Compare Algorithms\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seems that training a machine learning models is fairly easy task. However, real complexity arise from finding the best fitted model. And requires a lot of efforts on tuning model parameters. So we have run the model on the default parameters. Now it is time to search for the best model. \n",
    "\n",
    "### 6. Parameter Tuning. \n",
    "\n",
    "Well, we have got some idea about which one is performing with what accuracies. However, for each of the algorithm, it involves many parameters that requires tuning and settings to reach the goal. \n",
    "We will see how can to parameter tuning to get the best outcome. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the grid search function from sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:35:43.788858Z",
     "iopub.status.busy": "2024-10-16T23:35:43.787560Z",
     "iopub.status.idle": "2024-10-16T23:35:43.793776Z",
     "shell.execute_reply": "2024-10-16T23:35:43.792477Z",
     "shell.execute_reply.started": "2024-10-16T23:35:43.788800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the model and parameters values to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:36:13.051113Z",
     "iopub.status.busy": "2024-10-16T23:36:13.050662Z",
     "iopub.status.idle": "2024-10-16T23:36:13.060715Z",
     "shell.execute_reply": "2024-10-16T23:36:13.059549Z",
     "shell.execute_reply.started": "2024-10-16T23:36:13.051076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "LR=LogisticRegression(solver='liblinear')\n",
    "solvers=['lbfgs', 'sag', 'saga', 'newton-cg'] ## Possible solvers\n",
    "Cs=np.logspace(-3,3,7)  # possible range of values\n",
    "penalties=[\"l1\", 'l2'] ## possible regularizers\n",
    "max_iters=[50, 100, 200] ## range of iterations\n",
    "\n",
    "params=dict(C=Cs, penalty=penalties)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply grid search to find the best parameters from the values we have selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:36:16.934123Z",
     "iopub.status.busy": "2024-10-16T23:36:16.933699Z",
     "iopub.status.idle": "2024-10-16T23:36:16.939866Z",
     "shell.execute_reply": "2024-10-16T23:36:16.938463Z",
     "shell.execute_reply.started": "2024-10-16T23:36:16.934087Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grid=GridSearchCV(estimator=LR, param_grid=params, cv=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now train the model on the tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:36:21.384590Z",
     "iopub.status.busy": "2024-10-16T23:36:21.383731Z",
     "iopub.status.idle": "2024-10-16T23:36:21.774437Z",
     "shell.execute_reply": "2024-10-16T23:36:21.773370Z",
     "shell.execute_reply.started": "2024-10-16T23:36:21.384547Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access a number of elements from our grid search to know better about the best fitted model. \n",
    "\n",
    "For example, `what is the best score found?` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:36:43.669582Z",
     "iopub.status.busy": "2024-10-16T23:36:43.669206Z",
     "iopub.status.idle": "2024-10-16T23:36:43.675121Z",
     "shell.execute_reply": "2024-10-16T23:36:43.674058Z",
     "shell.execute_reply.started": "2024-10-16T23:36:43.669553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What are the best parameters?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:37:01.483664Z",
     "iopub.status.busy": "2024-10-16T23:37:01.483206Z",
     "iopub.status.idle": "2024-10-16T23:37:01.491417Z",
     "shell.execute_reply": "2024-10-16T23:37:01.490250Z",
     "shell.execute_reply.started": "2024-10-16T23:37:01.483631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`What is the best model/estimator built?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:37:08.633169Z",
     "iopub.status.busy": "2024-10-16T23:37:08.632720Z",
     "iopub.status.idle": "2024-10-16T23:37:08.638221Z",
     "shell.execute_reply": "2024-10-16T23:37:08.637029Z",
     "shell.execute_reply.started": "2024-10-16T23:37:08.633134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bestModel=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:37:32.208194Z",
     "iopub.status.busy": "2024-10-16T23:37:32.207711Z",
     "iopub.status.idle": "2024-10-16T23:37:32.216914Z",
     "shell.execute_reply": "2024-10-16T23:37:32.215756Z",
     "shell.execute_reply.started": "2024-10-16T23:37:32.208156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_pred=bestModel.predict(X_test)\n",
    "Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:37:37.870498Z",
     "iopub.status.busy": "2024-10-16T23:37:37.870109Z",
     "iopub.status.idle": "2024-10-16T23:37:37.884790Z",
     "shell.execute_reply": "2024-10-16T23:37:37.883563Z",
     "shell.execute_reply.started": "2024-10-16T23:37:37.870466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,Y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Building apps and deploying the best model and continous monitoring for drifting.\n",
    "This is an important but missing part from many ML lecture. \n",
    "\n",
    "Now that you have trained a model. You have built the best model. What to do next?\n",
    "\n",
    "The next thing is to save the model. And use it when you have a new data to classify. You don't need train the model every time. \n",
    "Train once. and use many times untill you have enough new data to training the model again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:39:27.371318Z",
     "iopub.status.busy": "2024-10-16T23:39:27.370115Z",
     "iopub.status.idle": "2024-10-16T23:39:27.376559Z",
     "shell.execute_reply": "2024-10-16T23:39:27.375334Z",
     "shell.execute_reply.started": "2024-10-16T23:39:27.371265Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pickle import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:39:49.691909Z",
     "iopub.status.busy": "2024-10-16T23:39:49.691114Z",
     "iopub.status.idle": "2024-10-16T23:39:49.697483Z",
     "shell.execute_reply": "2024-10-16T23:39:49.696226Z",
     "shell.execute_reply.started": "2024-10-16T23:39:49.691871Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dump(bestModel, open(\"bestModel.model\", 'wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:40:53.903055Z",
     "iopub.status.busy": "2024-10-16T23:40:53.902649Z",
     "iopub.status.idle": "2024-10-16T23:40:53.908615Z",
     "shell.execute_reply": "2024-10-16T23:40:53.907199Z",
     "shell.execute_reply.started": "2024-10-16T23:40:53.903024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model=load(open('bestModel.model', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the model to predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:41:08.095090Z",
     "iopub.status.busy": "2024-10-16T23:41:08.094083Z",
     "iopub.status.idle": "2024-10-16T23:41:08.101003Z",
     "shell.execute_reply": "2024-10-16T23:41:08.099454Z",
     "shell.execute_reply.started": "2024-10-16T23:41:08.095045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_pred=model.predict(X_test)\n",
    "#model.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-16T23:41:12.400321Z",
     "iopub.status.busy": "2024-10-16T23:41:12.399263Z",
     "iopub.status.idle": "2024-10-16T23:41:12.408056Z",
     "shell.execute_reply": "2024-10-16T23:41:12.406833Z",
     "shell.execute_reply.started": "2024-10-16T23:41:12.400282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hurray!! We have done a complete Machine learning project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task : Building and Evaluating a Machine Learning Model\n",
    "\n",
    "\n",
    "Task Description:\n",
    "Breast cancer is the most common cancer amongst women in the world. It accounts for 25% of all cancer cases and affected over 2.1 Million people in 2015 alone. It starts when cells in the breast begin to grow out of control. These cells usually form tumors that can be seen via X-ray or felt as lumps in the breast area.\n",
    "\n",
    "In this task, we will build and evaluate a machine learning model using the dataset we prepared earlier. We will follow these steps:\n",
    "\n",
    "1. Split the dataset into training and testing sets.\n",
    "2. Train a machine learning model on the training set.\n",
    "3. Evaluate the model's performance on the testing set.\n",
    "4. Save the best-performing model for future use.\n",
    "    \n",
    "Dataset link: https://www.kaggle.com/datasets/nancyalaswad90/breast-cancer-dataset/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pitch your best model and tell us why. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 727551,
     "sourceId": 1263738,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
