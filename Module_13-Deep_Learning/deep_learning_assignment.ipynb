{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/DTSC5502/blob/main/Module_13-Deep_Learning/deep_learning_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23TYuQVys4l1"
      },
      "source": [
        "# üß† Deep Learning Fundamentals: A Comprehensive Assignment\n",
        "\n",
        "## From ANNs to Transformers with PyTorch\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Assignment Overview\n",
        "\n",
        "In this assignment, you will explore the evolution of neural network architectures, from basic Artificial Neural Networks (ANNs) to modern Transformer models. You'll implement each architecture, understand their differences, and learn when to apply each one.\n",
        "\n",
        "### üéØ Learning Objectives\n",
        "\n",
        "By the end of this assignment, you will be able to:\n",
        "\n",
        "1. **Understand** the architecture and components of ANN, CNN, RNN, LSTM, GRU, Attention, and Transformers\n",
        "2. **Implement** each neural network type using PyTorch\n",
        "3. **Compare** the architectures and identify their strengths and weaknesses\n",
        "4. **Apply** appropriate activation functions, optimizers, and loss functions\n",
        "5. **Explain** forward propagation and backpropagation\n",
        "6. **Utilize** regularization techniques to prevent overfitting\n",
        "7. **Evaluate** models using appropriate metrics\n",
        "\n",
        "### üìö Table of Contents\n",
        "\n",
        "1. [Part 1: Setup and Fundamentals](#part1)\n",
        "2. [Part 2: Artificial Neural Networks (ANN)](#part2)\n",
        "3. [Part 3: Convolutional Neural Networks (CNN)](#part3)\n",
        "4. [Part 4: Recurrent Neural Networks (RNN)](#part4)\n",
        "5. [Part 5: Long Short-Term Memory (LSTM) & GRU](#part5)\n",
        "6. [Part 6: Attention Mechanisms](#part6)\n",
        "7. [Part 7: Transformers](#part7)\n",
        "8. [Part 8: Comparison and Analysis](#part8)\n",
        "9. [Part 9: Final Project](#part9)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsgzVd6Ls4l5"
      },
      "source": [
        "<a name=\"part1\"></a>\n",
        "# Part 1: Setup and Fundamentals\n",
        "\n",
        "## 1.1 Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEo7MJZRs4l5"
      },
      "outputs": [],
      "source": [
        "# Check if running on Google Colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running on Google Colab!\")\n",
        "    # Enable GPU\n",
        "    # Go to Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "else:\n",
        "    print(\"Running locally\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVlXtjWzs4l6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJWAsqUMs4l7"
      },
      "source": [
        "## 1.2 Understanding the Training Pipeline\n",
        "\n",
        "Before diving into architectures, let's understand the fundamental concepts that apply to ALL neural networks.\n",
        "\n",
        "### Forward Propagation\n",
        "Forward propagation is the process of passing input data through the network to get predictions:\n",
        "\n",
        "$$\\hat{y} = f(W_n \\cdot f(W_{n-1} \\cdot ... f(W_1 \\cdot x + b_1) ... + b_{n-1}) + b_n)$$\n",
        "\n",
        "### Backpropagation\n",
        "Backpropagation computes gradients of the loss with respect to weights using the chain rule:\n",
        "\n",
        "$$\\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial W}$$\n",
        "\n",
        "### The Training Loop\n",
        "```python\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataloader:\n",
        "        # 1. Forward pass\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # 2. Compute loss\n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        # 3. Backward pass (compute gradients)\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        loss.backward()        # Compute gradients\n",
        "        \n",
        "        # 4. Update weights\n",
        "        optimizer.step()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-fPMOn-s4l7"
      },
      "source": [
        "## 1.3 Activation Functions\n",
        "\n",
        "Activation functions introduce non-linearity into the network, allowing it to learn complex patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAVPZxkqs4l7"
      },
      "outputs": [],
      "source": [
        "# Visualize different activation functions\n",
        "x = torch.linspace(-5, 5, 100)\n",
        "\n",
        "# Define activation functions\n",
        "activations = {\n",
        "    'Sigmoid': torch.sigmoid(x),\n",
        "    'Tanh': torch.tanh(x),\n",
        "    'ReLU': F.relu(x),\n",
        "    'LeakyReLU': F.leaky_relu(x, 0.1),\n",
        "    'ELU': F.elu(x),\n",
        "    'GELU': F.gelu(x),\n",
        "    'Softplus': F.softplus(x),\n",
        "    'Swish/SiLU': F.silu(x)\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (name, y) in enumerate(activations.items()):\n",
        "    axes[idx].plot(x.numpy(), y.numpy(), 'b-', linewidth=2)\n",
        "    axes[idx].axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
        "    axes[idx].axvline(x=0, color='k', linestyle='-', linewidth=0.5)\n",
        "    axes[idx].set_title(name, fontsize=14)\n",
        "    axes[idx].set_xlabel('x')\n",
        "    axes[idx].set_ylabel('f(x)')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "    axes[idx].set_xlim(-5, 5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Activation Functions', fontsize=16, y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1aef8Ts4l8"
      },
      "source": [
        "### üìù Exercise 1.1: Activation Functions\n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "1. Why do we need activation functions in neural networks?\n",
        "2. What is the \"vanishing gradient problem\" and which activation functions suffer from it?\n",
        "3. Why is ReLU the most commonly used activation function?\n",
        "4. When would you use Sigmoid vs Softmax for the output layer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCv-PYEts4l8"
      },
      "source": [
        "**Your Answers:**\n",
        "\n",
        "1. [Your answer here]\n",
        "\n",
        "2. [Your answer here]\n",
        "\n",
        "3. [Your answer here]\n",
        "\n",
        "4. [Your answer here]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKa8-Da8s4l9"
      },
      "source": [
        "## 1.4 Loss Functions\n",
        "\n",
        "Loss functions measure how well our model's predictions match the actual targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSL4gpYds4l9"
      },
      "outputs": [],
      "source": [
        "# Demonstrate different loss functions\n",
        "\n",
        "# Sample predictions and targets\n",
        "predictions = torch.tensor([0.9, 0.2, 0.8, 0.1], dtype=torch.float32)\n",
        "targets_binary = torch.tensor([1.0, 0.0, 1.0, 0.0], dtype=torch.float32)\n",
        "\n",
        "predictions_reg = torch.tensor([2.5, 0.0, 2.1, 1.6], dtype=torch.float32)\n",
        "targets_reg = torch.tensor([3.0, -0.5, 2.0, 1.5], dtype=torch.float32)\n",
        "\n",
        "# Binary Cross-Entropy Loss (for binary classification)\n",
        "bce_loss = nn.BCELoss()\n",
        "print(f\"Binary Cross-Entropy Loss: {bce_loss(predictions, targets_binary):.4f}\")\n",
        "\n",
        "# Mean Squared Error Loss (for regression)\n",
        "mse_loss = nn.MSELoss()\n",
        "print(f\"MSE Loss: {mse_loss(predictions_reg, targets_reg):.4f}\")\n",
        "\n",
        "# Mean Absolute Error Loss (for regression)\n",
        "mae_loss = nn.L1Loss()\n",
        "print(f\"MAE Loss: {mae_loss(predictions_reg, targets_reg):.4f}\")\n",
        "\n",
        "# Cross-Entropy Loss (for multi-class classification)\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "predictions_multi = torch.tensor([[2.0, 1.0, 0.1], [0.5, 2.0, 0.3]], dtype=torch.float32)\n",
        "targets_multi = torch.tensor([0, 1], dtype=torch.long)\n",
        "print(f\"Cross-Entropy Loss: {ce_loss(predictions_multi, targets_multi):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFSCGk8Ks4l9"
      },
      "source": [
        "### Loss Function Selection Guide\n",
        "\n",
        "| Task | Loss Function | Output Activation |\n",
        "|------|---------------|-------------------|\n",
        "| Binary Classification | BCELoss or BCEWithLogitsLoss | Sigmoid |\n",
        "| Multi-class Classification | CrossEntropyLoss | None (raw logits) or Softmax |\n",
        "| Multi-label Classification | BCEWithLogitsLoss | Sigmoid |\n",
        "| Regression | MSELoss or L1Loss | None (linear) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BPDI7r0s4l9"
      },
      "source": [
        "## 1.5 Optimizers\n",
        "\n",
        "Optimizers update the network weights based on computed gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xSrIt5ps4l9"
      },
      "outputs": [],
      "source": [
        "# Visualize optimizer behavior on a simple loss landscape\n",
        "def rosenbrock(x, y):\n",
        "    \"\"\"Rosenbrock function - a common test function for optimization\"\"\"\n",
        "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
        "\n",
        "# Create a simple model to demonstrate optimizers\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, start_x, start_y):\n",
        "        super().__init__()\n",
        "        self.x = nn.Parameter(torch.tensor([start_x]))\n",
        "        self.y = nn.Parameter(torch.tensor([start_y]))\n",
        "\n",
        "    def forward(self):\n",
        "        return rosenbrock(self.x, self.y)\n",
        "\n",
        "def optimize_path(optimizer_class, lr, start_x=-1.0, start_y=1.0, steps=1000, **kwargs):\n",
        "    model = SimpleModel(start_x, start_y)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr, **kwargs)\n",
        "\n",
        "    path = [(model.x.item(), model.y.item())]\n",
        "\n",
        "    for _ in range(steps):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        path.append((model.x.item(), model.y.item()))\n",
        "\n",
        "    return path\n",
        "\n",
        "# Compare different optimizers\n",
        "optimizers_config = {\n",
        "    'SGD': (optim.SGD, {'lr': 0.001}),\n",
        "    'SGD + Momentum': (optim.SGD, {'lr': 0.001, 'momentum': 0.9}),\n",
        "    'Adam': (optim.Adam, {'lr': 0.01}),\n",
        "    'RMSprop': (optim.RMSprop, {'lr': 0.01}),\n",
        "}\n",
        "\n",
        "# Create contour plot\n",
        "x_range = np.linspace(-2, 2, 100)\n",
        "y_range = np.linspace(-1, 3, 100)\n",
        "X, Y = np.meshgrid(x_range, y_range)\n",
        "Z = rosenbrock(X, Y)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (name, (opt_class, params)) in enumerate(optimizers_config.items()):\n",
        "    path = optimize_path(opt_class, **params)\n",
        "    path = np.array(path)\n",
        "\n",
        "    axes[idx].contour(X, Y, Z, levels=np.logspace(-1, 3, 20), cmap='viridis', alpha=0.6)\n",
        "    axes[idx].plot(path[:, 0], path[:, 1], 'r.-', markersize=2, linewidth=1, alpha=0.7)\n",
        "    axes[idx].plot(path[0, 0], path[0, 1], 'go', markersize=10, label='Start')\n",
        "    axes[idx].plot(path[-1, 0], path[-1, 1], 'r*', markersize=15, label='End')\n",
        "    axes[idx].plot(1, 1, 'b^', markersize=10, label='Global Min')\n",
        "    axes[idx].set_title(f'{name}', fontsize=14)\n",
        "    axes[idx].set_xlabel('x')\n",
        "    axes[idx].set_ylabel('y')\n",
        "    axes[idx].legend()\n",
        "    axes[idx].set_xlim(-2, 2)\n",
        "    axes[idx].set_ylim(-1, 3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Optimizer Comparison on Rosenbrock Function', fontsize=16, y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htZ5y1E7s4l-"
      },
      "source": [
        "### Optimizer Summary\n",
        "\n",
        "| Optimizer | Key Features | Best For |\n",
        "|-----------|--------------|----------|\n",
        "| **SGD** | Simple, reliable | When you need fine control |\n",
        "| **SGD + Momentum** | Faster convergence, smooths updates | General purpose |\n",
        "| **Adam** | Adaptive learning rates, handles sparse gradients | Default choice, NLP |\n",
        "| **AdamW** | Adam with proper weight decay | Transformers |\n",
        "| **RMSprop** | Adaptive, handles non-stationary objectives | RNNs |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr2pA2-is4l-"
      },
      "source": [
        "## 1.6 Weight Initialization\n",
        "\n",
        "Proper initialization is crucial for training deep networks effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJjSEkVbs4l-"
      },
      "outputs": [],
      "source": [
        "# Demonstrate different initialization methods\n",
        "def visualize_initialization(init_fn, name, in_features=100, out_features=100):\n",
        "    layer = nn.Linear(in_features, out_features)\n",
        "    init_fn(layer.weight)\n",
        "    return layer.weight.data.numpy().flatten()\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "initializations = {\n",
        "    'Uniform [-1, 1]': lambda w: nn.init.uniform_(w, -1, 1),\n",
        "    'Normal (0, 1)': lambda w: nn.init.normal_(w, 0, 1),\n",
        "    'Xavier Uniform': nn.init.xavier_uniform_,\n",
        "    'Xavier Normal': nn.init.xavier_normal_,\n",
        "    'Kaiming Uniform (He)': lambda w: nn.init.kaiming_uniform_(w, mode='fan_in'),\n",
        "    'Kaiming Normal (He)': lambda w: nn.init.kaiming_normal_(w, mode='fan_in'),\n",
        "}\n",
        "\n",
        "for idx, (name, init_fn) in enumerate(initializations.items()):\n",
        "    weights = visualize_initialization(init_fn, name)\n",
        "    axes[idx].hist(weights, bins=50, density=True, alpha=0.7, color='steelblue')\n",
        "    axes[idx].set_title(f'{name}\\nŒº={weights.mean():.3f}, œÉ={weights.std():.3f}')\n",
        "    axes[idx].set_xlabel('Weight Value')\n",
        "    axes[idx].set_ylabel('Density')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Weight Initialization Methods', fontsize=16, y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZmy0HyLs4l-"
      },
      "source": [
        "### Initialization Guidelines\n",
        "\n",
        "- **Xavier/Glorot**: Use with Sigmoid or Tanh activations\n",
        "- **Kaiming/He**: Use with ReLU and its variants\n",
        "- **Orthogonal**: Good for RNNs\n",
        "- **Normal/Uniform**: Rarely the best choice for deep networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-512M1Zcs4l-"
      },
      "source": [
        "## 1.7 Regularization Techniques\n",
        "\n",
        "Regularization helps prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN0enmM_s4l_"
      },
      "outputs": [],
      "source": [
        "# Demonstrate Dropout\n",
        "class DropoutDemo(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(x)\n",
        "\n",
        "# Create sample input\n",
        "sample_input = torch.ones(1, 10)\n",
        "dropout_model = DropoutDemo(0.5)\n",
        "\n",
        "# Show dropout effect in training mode\n",
        "dropout_model.train()\n",
        "print(\"Training mode (dropout active):\")\n",
        "for i in range(3):\n",
        "    output = dropout_model(sample_input)\n",
        "    print(f\"  Pass {i+1}: {output.numpy().flatten()}\")\n",
        "\n",
        "# Show dropout effect in evaluation mode\n",
        "dropout_model.eval()\n",
        "print(\"\\nEvaluation mode (dropout inactive):\")\n",
        "for i in range(3):\n",
        "    output = dropout_model(sample_input)\n",
        "    print(f\"  Pass {i+1}: {output.numpy().flatten()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT67ECaBs4l_"
      },
      "outputs": [],
      "source": [
        "# Demonstrate L1 and L2 Regularization\n",
        "class RegularizedModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "    def l1_regularization(self, lambda_l1=0.01):\n",
        "        \"\"\"Calculate L1 regularization term\"\"\"\n",
        "        l1_norm = sum(p.abs().sum() for p in self.parameters())\n",
        "        return lambda_l1 * l1_norm\n",
        "\n",
        "    def l2_regularization(self, lambda_l2=0.01):\n",
        "        \"\"\"Calculate L2 regularization term\"\"\"\n",
        "        l2_norm = sum(p.pow(2).sum() for p in self.parameters())\n",
        "        return lambda_l2 * l2_norm\n",
        "\n",
        "# Example usage\n",
        "model = RegularizedModel(10, 20, 2)\n",
        "x = torch.randn(32, 10)\n",
        "y = torch.randint(0, 2, (32,))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "output = model(x)\n",
        "\n",
        "# Loss with regularization\n",
        "base_loss = criterion(output, y)\n",
        "l1_reg = model.l1_regularization(0.01)\n",
        "l2_reg = model.l2_regularization(0.01)\n",
        "\n",
        "print(f\"Base Loss: {base_loss.item():.4f}\")\n",
        "print(f\"L1 Regularization: {l1_reg.item():.4f}\")\n",
        "print(f\"L2 Regularization: {l2_reg.item():.4f}\")\n",
        "print(f\"Total Loss (with L2): {(base_loss + l2_reg).item():.4f}\")\n",
        "\n",
        "# Note: PyTorch's optimizers have built-in weight_decay for L2 regularization\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)  # weight_decay = L2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIPxOvJas4l_"
      },
      "source": [
        "## 1.8 Batch Normalization & Layer Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVhriuq5s4l_"
      },
      "outputs": [],
      "source": [
        "# Demonstrate Batch Normalization\n",
        "batch_size = 4\n",
        "features = 3\n",
        "\n",
        "# Create sample data\n",
        "x = torch.randn(batch_size, features) * 10 + 5  # Mean ~5, Std ~10\n",
        "print(\"Input:\")\n",
        "print(x)\n",
        "print(f\"Mean per feature: {x.mean(dim=0)}\")\n",
        "print(f\"Std per feature: {x.std(dim=0)}\")\n",
        "\n",
        "# Apply Batch Normalization\n",
        "bn = nn.BatchNorm1d(features)\n",
        "bn.train()  # Training mode\n",
        "x_bn = bn(x)\n",
        "\n",
        "print(\"\\nAfter Batch Normalization:\")\n",
        "print(x_bn)\n",
        "print(f\"Mean per feature: {x_bn.mean(dim=0)}\")\n",
        "print(f\"Std per feature: {x_bn.std(dim=0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdl02n3Hs4l_"
      },
      "outputs": [],
      "source": [
        "# Layer Normalization (commonly used in Transformers)\n",
        "seq_len = 4\n",
        "hidden_size = 3\n",
        "\n",
        "x = torch.randn(batch_size, seq_len, hidden_size) * 10 + 5\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Input[0]:\")\n",
        "print(x[0])\n",
        "\n",
        "# Apply Layer Normalization\n",
        "ln = nn.LayerNorm(hidden_size)\n",
        "x_ln = ln(x)\n",
        "\n",
        "print(\"\\nAfter Layer Normalization:\")\n",
        "print(x_ln[0])\n",
        "print(f\"\\nMean per token (should be ~0): {x_ln[0].mean(dim=-1)}\")\n",
        "print(f\"Std per token (should be ~1): {x_ln[0].std(dim=-1)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7NbFdi4s4l_"
      },
      "source": [
        "### Normalization Comparison\n",
        "\n",
        "| Type | Normalizes Over | Best For |\n",
        "|------|-----------------|----------|\n",
        "| **Batch Norm** | Batch dimension | CNNs, large batches |\n",
        "| **Layer Norm** | Feature dimension | Transformers, RNNs |\n",
        "| **Instance Norm** | Each sample independently | Style transfer |\n",
        "| **Group Norm** | Groups of channels | Small batch sizes |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz0TeCcKs4mA"
      },
      "source": [
        "## 1.9 Learning Rate Scheduling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHdEN9QNs4mA"
      },
      "outputs": [],
      "source": [
        "# Visualize different learning rate schedules\n",
        "def get_lr_schedule(scheduler_class, optimizer, epochs, **kwargs):\n",
        "    lrs = []\n",
        "    for _ in range(epochs):\n",
        "        lrs.append(optimizer.param_groups[0]['lr'])\n",
        "        scheduler_class.step()\n",
        "    return lrs\n",
        "\n",
        "# Create dummy model and optimizer\n",
        "dummy_model = nn.Linear(10, 1)\n",
        "epochs = 100\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "schedules = [\n",
        "    ('StepLR (step=30, Œ≥=0.1)', lambda opt: optim.lr_scheduler.StepLR(opt, step_size=30, gamma=0.1)),\n",
        "    ('ExponentialLR (Œ≥=0.95)', lambda opt: optim.lr_scheduler.ExponentialLR(opt, gamma=0.95)),\n",
        "    ('CosineAnnealingLR', lambda opt: optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)),\n",
        "    ('ReduceLROnPlateau', lambda opt: optim.lr_scheduler.ReduceLROnPlateau(opt, patience=10)),\n",
        "    ('OneCycleLR', lambda opt: optim.lr_scheduler.OneCycleLR(opt, max_lr=0.1, total_steps=epochs)),\n",
        "    ('CosineAnnealingWarmRestarts', lambda opt: optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=20)),\n",
        "]\n",
        "\n",
        "for idx, (name, scheduler_fn) in enumerate(schedules):\n",
        "    optimizer = optim.SGD(dummy_model.parameters(), lr=0.1)\n",
        "    scheduler = scheduler_fn(optimizer)\n",
        "\n",
        "    lrs = []\n",
        "    for epoch in range(epochs):\n",
        "        lrs.append(optimizer.param_groups[0]['lr'])\n",
        "        if 'Plateau' in name:\n",
        "            # Simulate varying loss\n",
        "            fake_loss = 1.0 / (epoch + 1) + np.random.random() * 0.1\n",
        "            scheduler.step(fake_loss)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "    axes[idx].plot(range(epochs), lrs, 'b-', linewidth=2)\n",
        "    axes[idx].set_title(name)\n",
        "    axes[idx].set_xlabel('Epoch')\n",
        "    axes[idx].set_ylabel('Learning Rate')\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Learning Rate Schedules', fontsize=16, y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJwjBAc4s4mA"
      },
      "source": [
        "## 1.10 Data Handling: Train/Validation/Test Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihBAtdYxs4mA"
      },
      "outputs": [],
      "source": [
        "# Demonstrate proper data splitting\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Create synthetic dataset\n",
        "n_samples = 1000\n",
        "X = torch.randn(n_samples, 10)\n",
        "y = torch.randint(0, 2, (n_samples,))\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "\n",
        "# Method 1: Using random_split\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset, [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(dataset)}\")\n",
        "print(f\"Training samples: {len(train_dataset)} ({len(train_dataset)/len(dataset)*100:.1f}%)\")\n",
        "print(f\"Validation samples: {len(val_dataset)} ({len(val_dataset)/len(dataset)*100:.1f}%)\")\n",
        "print(f\"Test samples: {len(test_dataset)} ({len(test_dataset)/len(dataset)*100:.1f}%)\")\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"\\nNumber of batches:\")\n",
        "print(f\"  Train: {len(train_loader)}\")\n",
        "print(f\"  Validation: {len(val_loader)}\")\n",
        "print(f\"  Test: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzNhzEJqs4mA"
      },
      "source": [
        "## 1.11 Utility Functions for Training\n",
        "\n",
        "Let's create reusable training and evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ii0xKqQDs4mA"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to stop training when validation loss doesn't improve.\"\"\"\n",
        "    def __init__(self, patience=7, min_delta=0, restore_best_weights=True):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.best_weights = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_weights = model.state_dict().copy()\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                if self.restore_best_weights:\n",
        "                    model.load_state_dict(self.best_weights)\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_weights = model.state_dict().copy()\n",
        "            self.counter = 0\n",
        "        return False\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return running_loss / len(train_loader), 100. * correct / total\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader, criterion, device):\n",
        "    \"\"\"Evaluate the model.\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    return running_loss / len(data_loader), 100. * correct / total, all_predictions, all_targets\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                num_epochs, device, scheduler=None, early_stopping=None):\n",
        "    \"\"\"Complete training loop with validation.\"\"\"\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        if scheduler:\n",
        "            if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                scheduler.step(val_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
        "                  f'Train Loss: {train_loss:.4f} Train Acc: {train_acc:.2f}% '\n",
        "                  f'Val Loss: {val_loss:.4f} Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "        if early_stopping and early_stopping(val_loss, model):\n",
        "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
        "            break\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def plot_training_history(history, title=\"Training History\"):\n",
        "    \"\"\"Plot training and validation metrics.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    ax1.plot(history['train_loss'], label='Train Loss')\n",
        "    ax1.plot(history['val_loss'], label='Val Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Loss over Epochs')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    ax2.plot(history['train_acc'], label='Train Accuracy')\n",
        "    ax2.plot(history['val_acc'], label='Val Accuracy')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.set_title('Accuracy over Epochs')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle(title, fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names=None):\n",
        "    \"\"\"Plot confusion matrix.\"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(\"Utility functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r1PRvA1s4mA"
      },
      "source": [
        "---\n",
        "<a name=\"part2\"></a>\n",
        "# Part 2: Artificial Neural Networks (ANN)\n",
        "\n",
        "## 2.1 Theory\n",
        "\n",
        "An **Artificial Neural Network (ANN)**, also known as a **Feedforward Neural Network** or **Multi-Layer Perceptron (MLP)**, is the simplest form of neural network.\n",
        "\n",
        "### Architecture\n",
        "- **Input Layer**: Receives input features\n",
        "- **Hidden Layers**: Process information through weighted connections\n",
        "- **Output Layer**: Produces predictions\n",
        "\n",
        "### Key Characteristics\n",
        "- Fully connected layers (each neuron connects to all neurons in adjacent layers)\n",
        "- Information flows in one direction (forward)\n",
        "- No memory of previous inputs\n",
        "- Works with fixed-size inputs\n",
        "\n",
        "### When to Use ANNs\n",
        "- Tabular/structured data\n",
        "- Classification tasks\n",
        "- Regression problems\n",
        "- When input features don't have spatial or temporal relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u90Hdzes4mB"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset for ANN demonstration\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Download and load training data\n",
        "train_dataset_full = torchvision.datasets.MNIST(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data', train=False, download=True, transform=transform\n",
        ")\n",
        "\n",
        "# Split training into train and validation\n",
        "train_size = int(0.9 * len(train_dataset_full))\n",
        "val_size = len(train_dataset_full) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset_full, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader_mnist = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader_mnist = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader_mnist = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Visualize some samples\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    img, label = train_dataset_full[i]\n",
        "    ax.imshow(img.squeeze(), cmap='gray')\n",
        "    ax.set_title(f'Label: {label}')\n",
        "    ax.axis('off')\n",
        "plt.suptitle('MNIST Sample Images', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V1JktwKs4mB"
      },
      "source": [
        "## 2.2 Building an ANN from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM87eF6Hs4mB"
      },
      "outputs": [],
      "source": [
        "class ANN(nn.Module):\n",
        "    \"\"\"\n",
        "    Artificial Neural Network (Multi-Layer Perceptron)\n",
        "\n",
        "    Architecture:\n",
        "    Input (784) -> FC(512) -> ReLU -> Dropout -> FC(256) -> ReLU -> Dropout -> FC(10)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=784, hidden_sizes=[512, 256], num_classes=10, dropout_rate=0.2):\n",
        "        super(ANN, self).__init__()\n",
        "\n",
        "        # Build layers dynamically\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_size, hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ])\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        layers.append(nn.Linear(prev_size, num_classes))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "        # Initialize weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten input: (batch_size, 1, 28, 28) -> (batch_size, 784)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.network(x)\n",
        "\n",
        "# Create model\n",
        "ann_model = ANN().to(device)\n",
        "print(ann_model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in ann_model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECAy4Eyvs4mB"
      },
      "outputs": [],
      "source": [
        "# Train the ANN\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(ann_model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "print(\"Training ANN on MNIST...\\n\")\n",
        "ann_history = train_model(\n",
        "    ann_model, train_loader_mnist, val_loader_mnist, criterion, optimizer,\n",
        "    num_epochs=20, device=device, scheduler=scheduler, early_stopping=early_stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnXRx2Q0s4mB"
      },
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plot_training_history(ann_history, \"ANN Training History\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc, predictions, targets = evaluate(ann_model, test_loader_mnist, criterion, device)\n",
        "print(f\"\\nTest Results: Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(targets, predictions, digits=4))\n",
        "\n",
        "# Confusion matrix\n",
        "plot_confusion_matrix(targets, predictions, class_names=[str(i) for i in range(10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqRLSLxJs4mC"
      },
      "source": [
        "### üìù Exercise 2.1: Modify the ANN\n",
        "\n",
        "Experiment with the ANN architecture:\n",
        "\n",
        "1. Add more hidden layers\n",
        "2. Change the number of neurons\n",
        "3. Try different activation functions\n",
        "4. Adjust the dropout rate\n",
        "\n",
        "Document your findings below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9UDEiNos4mC"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE: Create a modified ANN\n",
        "class ModifiedANN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedANN, self).__init__()\n",
        "        # TODO: Implement your modified architecture\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass\n",
        "        pass\n",
        "\n",
        "# Train and compare with the original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgp7vQNQs4mM"
      },
      "source": [
        "**Your Findings:**\n",
        "\n",
        "[Document what you observed when modifying the architecture]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVWhjZfos4mM"
      },
      "source": [
        "---\n",
        "<a name=\"part3\"></a>\n",
        "# Part 3: Convolutional Neural Networks (CNN)\n",
        "\n",
        "## 3.1 Theory\n",
        "\n",
        "**Convolutional Neural Networks** are designed to process data with grid-like topology, such as images.\n",
        "\n",
        "### Key Components\n",
        "\n",
        "1. **Convolutional Layers**: Apply learnable filters to detect features\n",
        "2. **Pooling Layers**: Reduce spatial dimensions while retaining important information\n",
        "3. **Fully Connected Layers**: Final classification/regression\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "- **Local Connectivity**: Each neuron connects only to a small region of the input\n",
        "- **Parameter Sharing**: Same filter is used across the entire input\n",
        "- **Translation Invariance**: Can detect features regardless of position\n",
        "\n",
        "### When to Use CNNs\n",
        "- Image classification\n",
        "- Object detection\n",
        "- Image segmentation\n",
        "- Any data with spatial structure (audio spectrograms, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyjjoZ1Es4mM"
      },
      "outputs": [],
      "source": [
        "# Visualize convolution operation\n",
        "def visualize_convolution():\n",
        "    # Create a simple image\n",
        "    image = torch.zeros(1, 1, 8, 8)\n",
        "    image[0, 0, 2:6, 2:6] = 1  # White square in center\n",
        "\n",
        "    # Define filters\n",
        "    edge_detector_h = torch.tensor([[-1, -1, -1],\n",
        "                                     [ 0,  0,  0],\n",
        "                                     [ 1,  1,  1]], dtype=torch.float32).view(1, 1, 3, 3)\n",
        "\n",
        "    edge_detector_v = torch.tensor([[-1,  0,  1],\n",
        "                                     [-1,  0,  1],\n",
        "                                     [-1,  0,  1]], dtype=torch.float32).view(1, 1, 3, 3)\n",
        "\n",
        "    # Apply convolutions\n",
        "    output_h = F.conv2d(image, edge_detector_h, padding=1)\n",
        "    output_v = F.conv2d(image, edge_detector_v, padding=1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "    axes[0].imshow(image.squeeze(), cmap='gray')\n",
        "    axes[0].set_title('Original Image')\n",
        "\n",
        "    axes[1].imshow(edge_detector_h.squeeze(), cmap='RdBu')\n",
        "    axes[1].set_title('Horizontal Edge Filter')\n",
        "\n",
        "    axes[2].imshow(output_h.squeeze().detach(), cmap='RdBu')\n",
        "    axes[2].set_title('Horizontal Edges Detected')\n",
        "\n",
        "    axes[3].imshow(output_v.squeeze().detach(), cmap='RdBu')\n",
        "    axes[3].set_title('Vertical Edges Detected')\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_convolution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOdHWE_-s4mN"
      },
      "outputs": [],
      "source": [
        "# Visualize pooling operations\n",
        "def visualize_pooling():\n",
        "    # Create sample feature map\n",
        "    feature_map = torch.tensor([[[[1, 2, 3, 4],\n",
        "                                   [5, 6, 7, 8],\n",
        "                                   [9, 10, 11, 12],\n",
        "                                   [13, 14, 15, 16]]]], dtype=torch.float32)\n",
        "\n",
        "    max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    max_pooled = max_pool(feature_map)\n",
        "    avg_pooled = avg_pool(feature_map)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "    # Original\n",
        "    im0 = axes[0].imshow(feature_map.squeeze(), cmap='viridis')\n",
        "    axes[0].set_title('Original (4x4)')\n",
        "    for i in range(4):\n",
        "        for j in range(4):\n",
        "            axes[0].text(j, i, f'{int(feature_map[0,0,i,j])}', ha='center', va='center', color='white')\n",
        "\n",
        "    # Max Pooled\n",
        "    im1 = axes[1].imshow(max_pooled.squeeze(), cmap='viridis')\n",
        "    axes[1].set_title('Max Pooled (2x2)')\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            axes[1].text(j, i, f'{int(max_pooled[0,0,i,j])}', ha='center', va='center', color='white')\n",
        "\n",
        "    # Avg Pooled\n",
        "    im2 = axes[2].imshow(avg_pooled.squeeze(), cmap='viridis')\n",
        "    axes[2].set_title('Avg Pooled (2x2)')\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            axes[2].text(j, i, f'{avg_pooled[0,0,i,j]:.1f}', ha='center', va='center', color='white')\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_pooling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n4RaNW9s4mN"
      },
      "source": [
        "## 3.2 Building a CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0GT0eQQs4mN"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Neural Network for image classification.\n",
        "\n",
        "    Architecture:\n",
        "    Conv1(32) -> BN -> ReLU -> MaxPool ->\n",
        "    Conv2(64) -> BN -> ReLU -> MaxPool ->\n",
        "    Conv3(128) -> BN -> ReLU -> MaxPool ->\n",
        "    Flatten -> FC(256) -> ReLU -> Dropout -> FC(10)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        # After 3 pooling operations: 28 -> 14 -> 7 -> 3\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional blocks\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # 28->14\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # 14->7\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # 7->3\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Fully connected\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "cnn_model = CNN().to(device)\n",
        "print(cnn_model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in cnn_model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUpzno_ls4mN"
      },
      "outputs": [],
      "source": [
        "# Train the CNN\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n",
        "early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "print(\"Training CNN on MNIST...\\n\")\n",
        "cnn_history = train_model(\n",
        "    cnn_model, train_loader_mnist, val_loader_mnist, criterion, optimizer,\n",
        "    num_epochs=20, device=device, scheduler=scheduler, early_stopping=early_stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB-ZqL7is4mN"
      },
      "outputs": [],
      "source": [
        "# Plot training history and evaluate\n",
        "plot_training_history(cnn_history, \"CNN Training History\")\n",
        "\n",
        "test_loss, test_acc, predictions, targets = evaluate(cnn_model, test_loader_mnist, criterion, device)\n",
        "print(f\"\\nTest Results: Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h_oOIlLs4mN"
      },
      "outputs": [],
      "source": [
        "# Visualize learned filters from first conv layer\n",
        "def visualize_filters(model):\n",
        "    filters = model.conv1.weight.data.cpu()\n",
        "    n_filters = filters.shape[0]\n",
        "\n",
        "    fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(min(32, n_filters)):\n",
        "        axes[i].imshow(filters[i, 0], cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f'Filter {i+1}')\n",
        "\n",
        "    plt.suptitle('Learned Filters (First Conv Layer)', fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_filters(cnn_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeWj01R1s4mO"
      },
      "source": [
        "### üìù Exercise 3.1: CNN Feature Maps\n",
        "\n",
        "Visualize the feature maps at different layers of the CNN for a sample image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPOhmw98s4mO"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE: Visualize feature maps\n",
        "def visualize_feature_maps(model, image):\n",
        "    \"\"\"\n",
        "    Pass an image through the CNN and visualize intermediate feature maps.\n",
        "\n",
        "    Hint: Use forward hooks or manually pass through each layer\n",
        "    \"\"\"\n",
        "    # TODO: Implement feature map visualization\n",
        "    pass\n",
        "\n",
        "# Get a sample image\n",
        "sample_image, label = test_dataset[0]\n",
        "# visualize_feature_maps(cnn_model, sample_image.unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM9mgwcks4mO"
      },
      "source": [
        "## 3.3 Data Augmentation for CNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQOSpoSys4mO"
      },
      "outputs": [],
      "source": [
        "# Demonstrate data augmentation\n",
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "])\n",
        "\n",
        "# Get a sample image\n",
        "original_image, label = train_dataset_full[0]\n",
        "\n",
        "# Apply augmentations\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "axes[0].imshow(original_image.squeeze(), cmap='gray')\n",
        "axes[0].set_title('Original')\n",
        "axes[0].axis('off')\n",
        "\n",
        "for i in range(1, 10):\n",
        "    # Convert to PIL for augmentation\n",
        "    pil_image = transforms.ToPILImage()(original_image)\n",
        "    augmented = augmentation_transforms(pil_image)\n",
        "    axes[i].imshow(augmented, cmap='gray')\n",
        "    axes[i].set_title(f'Augmented {i}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Data Augmentation Examples', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc2Bxwkys4mO"
      },
      "source": [
        "---\n",
        "<a name=\"part4\"></a>\n",
        "# Part 4: Recurrent Neural Networks (RNN)\n",
        "\n",
        "## 4.1 Theory\n",
        "\n",
        "**Recurrent Neural Networks** are designed for sequential data where the order matters.\n",
        "\n",
        "### Key Characteristics\n",
        "\n",
        "- **Memory**: Maintains hidden state that captures information from previous time steps\n",
        "- **Weight Sharing**: Same weights used across all time steps\n",
        "- **Variable-Length Input**: Can process sequences of any length\n",
        "\n",
        "### The Hidden State\n",
        "$$h_t = \\tanh(W_{hh} \\cdot h_{t-1} + W_{xh} \\cdot x_t + b_h)$$\n",
        "$$y_t = W_{hy} \\cdot h_t + b_y$$\n",
        "\n",
        "### When to Use RNNs\n",
        "- Time series prediction\n",
        "- Natural language processing\n",
        "- Speech recognition\n",
        "- Any sequential data\n",
        "\n",
        "### Limitations\n",
        "- **Vanishing Gradient Problem**: Gradients become very small during backpropagation through time\n",
        "- **Short-term Memory**: Difficulty learning long-range dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYwhEJXVs4mP"
      },
      "outputs": [],
      "source": [
        "# Create a synthetic sequence dataset for RNN demonstration\n",
        "def generate_sequence_data(n_samples=1000, seq_length=50, n_features=1):\n",
        "    \"\"\"\n",
        "    Generate synthetic time series data.\n",
        "    Task: Predict if the sum of the sequence is positive or negative.\n",
        "    \"\"\"\n",
        "    X = torch.randn(n_samples, seq_length, n_features)\n",
        "    y = (X.sum(dim=(1, 2)) > 0).long()  # Binary classification\n",
        "    return X, y\n",
        "\n",
        "# Generate data\n",
        "X_seq, y_seq = generate_sequence_data(n_samples=5000)\n",
        "\n",
        "# Split data\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_seq, y_seq, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset_seq = TensorDataset(X_train, y_train)\n",
        "val_dataset_seq = TensorDataset(X_val, y_val)\n",
        "test_dataset_seq = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader_seq = DataLoader(train_dataset_seq, batch_size=64, shuffle=True)\n",
        "val_loader_seq = DataLoader(val_dataset_seq, batch_size=64, shuffle=False)\n",
        "test_loader_seq = DataLoader(test_dataset_seq, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset_seq)}\")\n",
        "print(f\"Sequence shape: {X_train.shape}\")\n",
        "print(f\"Class distribution - 0: {(y_train == 0).sum().item()}, 1: {(y_train == 1).sum().item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAZKw1f9s4mP"
      },
      "source": [
        "## 4.2 Building an RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Uh5rpaos4mP"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple Recurrent Neural Network.\n",
        "\n",
        "    Architecture:\n",
        "    Input -> RNN layers -> FC -> Output\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, num_classes=2, dropout=0.3):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # RNN layer\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,  # Input shape: (batch, seq, features)\n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            nonlinearity='tanh'\n",
        "        )\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward through RNN\n",
        "        # out: (batch, seq_len, hidden_size)\n",
        "        # hidden: (num_layers, batch, hidden_size)\n",
        "        out, hidden = self.rnn(x, h0)\n",
        "\n",
        "        # Use the last time step's output\n",
        "        out = out[:, -1, :]  # (batch, hidden_size)\n",
        "\n",
        "        # Fully connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Create model\n",
        "rnn_model = SimpleRNN().to(device)\n",
        "print(rnn_model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in rnn_model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j3h6oq7s4mP"
      },
      "outputs": [],
      "source": [
        "# Train the RNN\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "print(\"Training RNN on sequence data...\\n\")\n",
        "rnn_history = train_model(\n",
        "    rnn_model, train_loader_seq, val_loader_seq, criterion, optimizer,\n",
        "    num_epochs=30, device=device, scheduler=scheduler, early_stopping=early_stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2ZxXtdas4mP"
      },
      "outputs": [],
      "source": [
        "plot_training_history(rnn_history, \"Simple RNN Training History\")\n",
        "\n",
        "test_loss, test_acc, _, _ = evaluate(rnn_model, test_loader_seq, criterion, device)\n",
        "print(f\"\\nTest Results: Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k83DZSLzs4mQ"
      },
      "source": [
        "## 4.3 Visualizing the Vanishing Gradient Problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJPbiGuUs4mQ"
      },
      "outputs": [],
      "source": [
        "# Demonstrate vanishing gradients\n",
        "def analyze_gradients(model, data_loader, device):\n",
        "    \"\"\"Analyze gradient magnitudes across time steps.\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    # Get a batch\n",
        "    inputs, targets = next(iter(data_loader))\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Get gradients from RNN layer\n",
        "    gradients = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.grad is not None:\n",
        "            gradients[name] = param.grad.abs().mean().item()\n",
        "\n",
        "    return gradients\n",
        "\n",
        "# Analyze gradients\n",
        "rnn_gradients = analyze_gradients(rnn_model, train_loader_seq, device)\n",
        "\n",
        "print(\"Gradient magnitudes:\")\n",
        "for name, grad_mag in rnn_gradients.items():\n",
        "    print(f\"  {name}: {grad_mag:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kufeibtPs4mQ"
      },
      "source": [
        "### üìù Exercise 4.1: RNN for Sequence Classification\n",
        "\n",
        "Modify the RNN to:\n",
        "1. Use bidirectional processing\n",
        "2. Use attention over all time steps instead of just the last one\n",
        "\n",
        "Compare the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDKoFWuJs4mQ"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE: Create a Bidirectional RNN\n",
        "class BidirectionalRNN(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, num_classes=2):\n",
        "        super(BidirectionalRNN, self).__init__()\n",
        "        # TODO: Implement bidirectional RNN\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement forward pass\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9OJ1nJJs4mQ"
      },
      "source": [
        "---\n",
        "<a name=\"part5\"></a>\n",
        "# Part 5: LSTM & GRU\n",
        "\n",
        "## 5.1 LSTM Theory\n",
        "\n",
        "**Long Short-Term Memory (LSTM)** networks solve the vanishing gradient problem through a gating mechanism.\n",
        "\n",
        "### LSTM Gates\n",
        "\n",
        "1. **Forget Gate**: Decides what information to discard from cell state\n",
        "   $$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$$\n",
        "\n",
        "2. **Input Gate**: Decides what new information to store\n",
        "   $$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$$\n",
        "   $$\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$$\n",
        "\n",
        "3. **Cell State Update**:\n",
        "   $$C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$$\n",
        "\n",
        "4. **Output Gate**: Decides what to output\n",
        "   $$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$$\n",
        "   $$h_t = o_t \\odot \\tanh(C_t)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrQyl7RIs4mQ"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Long Short-Term Memory Network.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, num_classes=2, dropout=0.3):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward through LSTM\n",
        "        out, (hidden, cell) = self.lstm(x, (h0, c0))\n",
        "\n",
        "        # Use the last time step's output\n",
        "        out = out[:, -1, :]\n",
        "        out = self.layer_norm(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Create and train LSTM\n",
        "lstm_model = LSTM().to(device)\n",
        "print(lstm_model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh5zXXpLs4mR"
      },
      "outputs": [],
      "source": [
        "# Train LSTM\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "print(\"Training LSTM...\\n\")\n",
        "lstm_history = train_model(\n",
        "    lstm_model, train_loader_seq, val_loader_seq, criterion, optimizer,\n",
        "    num_epochs=30, device=device, scheduler=scheduler, early_stopping=early_stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wcLNVsHs4mR"
      },
      "source": [
        "## 5.2 GRU (Gated Recurrent Unit)\n",
        "\n",
        "GRU is a simplified version of LSTM with fewer parameters.\n",
        "\n",
        "### GRU Gates\n",
        "\n",
        "1. **Update Gate**: Combines forget and input gates\n",
        "   $$z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$$\n",
        "\n",
        "2. **Reset Gate**: Controls how much past information to forget\n",
        "   $$r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$$\n",
        "\n",
        "3. **Hidden State**:\n",
        "   $$\\tilde{h}_t = \\tanh(W \\cdot [r_t \\odot h_{t-1}, x_t])$$\n",
        "   $$h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cFkHLTIs4mR"
      },
      "outputs": [],
      "source": [
        "class GRU(nn.Module):\n",
        "    \"\"\"\n",
        "    Gated Recurrent Unit Network.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, num_classes=2, dropout=0.3):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # GRU layer\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward through GRU\n",
        "        out, hidden = self.gru(x, h0)\n",
        "\n",
        "        # Use the last time step's output\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Create and train GRU\n",
        "gru_model = GRU().to(device)\n",
        "print(gru_model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in gru_model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIEYr1hTs4mR"
      },
      "outputs": [],
      "source": [
        "# Train GRU\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "print(\"Training GRU...\\n\")\n",
        "gru_history = train_model(\n",
        "    gru_model, train_loader_seq, val_loader_seq, criterion, optimizer,\n",
        "    num_epochs=30, device=device, scheduler=scheduler, early_stopping=early_stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X978rrXgs4mR"
      },
      "outputs": [],
      "source": [
        "# Compare RNN, LSTM, and GRU\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss comparison\n",
        "axes[0].plot(rnn_history['val_loss'], label='RNN', alpha=0.8)\n",
        "axes[0].plot(lstm_history['val_loss'], label='LSTM', alpha=0.8)\n",
        "axes[0].plot(gru_history['val_loss'], label='GRU', alpha=0.8)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Validation Loss')\n",
        "axes[0].set_title('Validation Loss Comparison')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy comparison\n",
        "axes[1].plot(rnn_history['val_acc'], label='RNN', alpha=0.8)\n",
        "axes[1].plot(lstm_history['val_acc'], label='LSTM', alpha=0.8)\n",
        "axes[1].plot(gru_history['val_acc'], label='GRU', alpha=0.8)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Validation Accuracy (%)')\n",
        "axes[1].set_title('Validation Accuracy Comparison')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final test results\n",
        "print(\"\\nFinal Test Results:\")\n",
        "print(\"-\" * 40)\n",
        "for name, model in [('RNN', rnn_model), ('LSTM', lstm_model), ('GRU', gru_model)]:\n",
        "    test_loss, test_acc, _, _ = evaluate(model, test_loader_seq, criterion, device)\n",
        "    params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"{name:6s} - Accuracy: {test_acc:.2f}%, Loss: {test_loss:.4f}, Params: {params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmuMhwBGs4mR"
      },
      "source": [
        "### üìù Exercise 5.1: LSTM vs GRU Analysis\n",
        "\n",
        "1. Which model performed better and why?\n",
        "2. How do the number of parameters compare?\n",
        "3. Try increasing the sequence length to 100 and 200. How does each model perform?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpSwONj0s4mS"
      },
      "source": [
        "**Your Analysis:**\n",
        "\n",
        "[Write your analysis here]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEqcPN6xs4mS"
      },
      "source": [
        "---\n",
        "<a name=\"part6\"></a>\n",
        "# Part 6: Attention Mechanisms\n",
        "\n",
        "## 6.1 Theory\n",
        "\n",
        "**Attention** allows the model to focus on relevant parts of the input when making predictions.\n",
        "\n",
        "### Basic Attention Formula\n",
        "\n",
        "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
        "\n",
        "Where:\n",
        "- **Q (Query)**: What we're looking for\n",
        "- **K (Key)**: What we're matching against\n",
        "- **V (Value)**: What we retrieve\n",
        "- **d_k**: Dimension of keys (for scaling)\n",
        "\n",
        "### Types of Attention\n",
        "1. **Self-Attention**: Q, K, V all come from the same sequence\n",
        "2. **Cross-Attention**: Q comes from one sequence, K and V from another\n",
        "3. **Multi-Head Attention**: Multiple attention operations in parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAq_n0KEs4mS"
      },
      "outputs": [],
      "source": [
        "# Visualize attention mechanism\n",
        "def visualize_attention_concept():\n",
        "    # Simulate attention weights for a sentence\n",
        "    words = ['The', 'cat', 'sat', 'on', 'the', 'mat']\n",
        "    query_word = 'sat'\n",
        "\n",
        "    # Simulated attention scores (higher = more relevant)\n",
        "    attention_scores = torch.tensor([0.1, 0.4, 1.0, 0.2, 0.05, 0.15])\n",
        "    attention_weights = F.softmax(attention_scores, dim=0)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "    # Raw scores\n",
        "    axes[0].bar(words, attention_scores.numpy(), color='steelblue')\n",
        "    axes[0].set_title(f'Raw Attention Scores (Query: \"{query_word}\")')\n",
        "    axes[0].set_ylabel('Score')\n",
        "\n",
        "    # Softmax weights\n",
        "    axes[1].bar(words, attention_weights.numpy(), color='coral')\n",
        "    axes[1].set_title(f'Attention Weights after Softmax')\n",
        "    axes[1].set_ylabel('Weight')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_attention_concept()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntwaBDJys4mS"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Scaled Dot-Product Attention.\n",
        "\n",
        "    Attention(Q, K, V) = softmax(QK^T / sqrt(d_k)) * V\n",
        "    \"\"\"\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            query: (batch, seq_len, d_k)\n",
        "            key: (batch, seq_len, d_k)\n",
        "            value: (batch, seq_len, d_v)\n",
        "            mask: Optional attention mask\n",
        "        \"\"\"\n",
        "        d_k = query.size(-1)\n",
        "\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / np.sqrt(d_k)\n",
        "\n",
        "        # Apply mask (optional)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        # Softmax to get attention weights\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        output = torch.matmul(attention_weights, value)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "# Test the attention module\n",
        "batch_size = 2\n",
        "seq_len = 4\n",
        "d_model = 8\n",
        "\n",
        "attention = ScaledDotProductAttention()\n",
        "q = torch.randn(batch_size, seq_len, d_model)\n",
        "k = torch.randn(batch_size, seq_len, d_model)\n",
        "v = torch.randn(batch_size, seq_len, d_model)\n",
        "\n",
        "output, weights = attention(q, k, v)\n",
        "print(f\"Input shape: {q.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Attention weights shape: {weights.shape}\")\n",
        "print(f\"\\nAttention weights (first batch):\\n{weights[0].detach().numpy().round(3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BIEdl1Vs4mS"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-Head Attention.\n",
        "\n",
        "    Runs multiple attention operations in parallel, then concatenates results.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        # Linear projections\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        batch_size = query.size(0)\n",
        "\n",
        "        # Linear projections and reshape for multi-head\n",
        "        # (batch, seq_len, d_model) -> (batch, num_heads, seq_len, d_k)\n",
        "        query = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        key = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        value = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Apply attention\n",
        "        attn_output, attn_weights = self.attention(query, key, value, mask)\n",
        "\n",
        "        # Concatenate heads\n",
        "        # (batch, num_heads, seq_len, d_k) -> (batch, seq_len, d_model)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "\n",
        "        # Final linear projection\n",
        "        output = self.W_o(attn_output)\n",
        "\n",
        "        return output, attn_weights\n",
        "\n",
        "# Test multi-head attention\n",
        "mha = MultiHeadAttention(d_model=64, num_heads=8)\n",
        "x = torch.randn(2, 10, 64)  # (batch, seq_len, d_model)\n",
        "output, weights = mha(x, x, x)  # Self-attention\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Attention weights shape: {weights.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW38UTPYs4mS"
      },
      "source": [
        "## 6.2 LSTM with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlcjLlQss4mT"
      },
      "outputs": [],
      "source": [
        "class LSTMWithAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM with self-attention mechanism.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, num_classes=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention layer\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=hidden_size,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Layer norm\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        # Output layers\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Initialize hidden states\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "\n",
        "        # LSTM forward\n",
        "        lstm_out, _ = self.lstm(x, (h0, c0))  # (batch, seq_len, hidden_size)\n",
        "\n",
        "        # Self-attention over LSTM outputs\n",
        "        attn_out, attn_weights = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "\n",
        "        # Residual connection and layer norm\n",
        "        attn_out = self.layer_norm(lstm_out + attn_out)\n",
        "\n",
        "        # Global average pooling over sequence\n",
        "        pooled = attn_out.mean(dim=1)  # (batch, hidden_size)\n",
        "\n",
        "        # Output\n",
        "        out = self.dropout(pooled)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Create and train LSTM with Attention\n",
        "lstm_attn_model = LSTMWithAttention().to(device)\n",
        "print(lstm_attn_model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in lstm_attn_model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96-KTn9Rs4mT"
      },
      "outputs": [],
      "source": [
        "# Train LSTM with Attention\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lstm_attn_model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "print(\"Training LSTM with Attention...\\n\")\n",
        "lstm_attn_history = train_model(\n",
        "    lstm_attn_model, train_loader_seq, val_loader_seq, criterion, optimizer,\n",
        "    num_epochs=30, device=device, scheduler=scheduler, early_stopping=early_stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QDzExnps4mT"
      },
      "outputs": [],
      "source": [
        "plot_training_history(lstm_attn_history, \"LSTM with Attention Training History\")\n",
        "\n",
        "test_loss, test_acc, _, _ = evaluate(lstm_attn_model, test_loader_seq, criterion, device)\n",
        "print(f\"\\nTest Results: Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QsVOmQMs4mT"
      },
      "source": [
        "---\n",
        "<a name=\"part7\"></a>\n",
        "# Part 7: Transformers\n",
        "\n",
        "## 7.1 Theory\n",
        "\n",
        "**Transformers** use self-attention as the primary mechanism, completely eliminating recurrence.\n",
        "\n",
        "### Key Components\n",
        "\n",
        "1. **Positional Encoding**: Injects sequence position information\n",
        "2. **Multi-Head Attention**: Parallel attention operations\n",
        "3. **Feed-Forward Network**: Position-wise fully connected layers\n",
        "4. **Residual Connections**: Skip connections around each sub-layer\n",
        "5. **Layer Normalization**: Normalizes inputs to each sub-layer\n",
        "\n",
        "### Advantages over RNNs\n",
        "- Parallelizable (no sequential dependency)\n",
        "- Better at capturing long-range dependencies\n",
        "- More efficient training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oxVWtjws4mT"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding using sine and cosine functions.\n",
        "\n",
        "    PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
        "    PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Create positional encoding matrix\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch, seq_len, d_model)\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "# Visualize positional encoding\n",
        "pe = PositionalEncoding(d_model=64, max_len=100, dropout=0)\n",
        "dummy_input = torch.zeros(1, 100, 64)\n",
        "pe_output = pe(dummy_input)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(pe.pe[0, :50, :].numpy(), aspect='auto', cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Dimension')\n",
        "plt.ylabel('Position')\n",
        "plt.title('Positional Encoding Visualization')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_VchLdJs4mT"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Single Transformer Encoder block.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.self_attn = nn.MultiheadAttention(\n",
        "            embed_dim=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Feed-forward network\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Layer normalization\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Self-attention with residual connection\n",
        "        attn_out, attn_weights = self.self_attn(x, x, x, attn_mask=mask)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "\n",
        "        # Feed-forward with residual connection\n",
        "        ffn_out = self.ffn(x)\n",
        "        x = self.norm2(x + ffn_out)\n",
        "\n",
        "        return x, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZjXwyY3s4mU"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer model for sequence classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=1, d_model=64, num_heads=4, num_layers=2,\n",
        "                 d_ff=256, num_classes=2, max_len=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input projection\n",
        "        self.input_proj = nn.Linear(input_size, d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len, dropout)\n",
        "\n",
        "        # Transformer encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([\n",
        "            TransformerEncoderBlock(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # Classification head\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model, num_classes)\n",
        "        )\n",
        "\n",
        "        # CLS token (learnable)\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Project input\n",
        "        x = self.input_proj(x)  # (batch, seq_len, d_model)\n",
        "\n",
        "        # Add CLS token\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
        "        x = torch.cat([cls_tokens, x], dim=1)  # (batch, seq_len+1, d_model)\n",
        "\n",
        "        # Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "\n",
        "        # Pass through encoder layers\n",
        "        attn_weights_list = []\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            x, attn_weights = encoder_layer(x)\n",
        "            attn_weights_list.append(attn_weights)\n",
        "\n",
        "        # Use CLS token for classification\n",
        "        cls_output = x[:, 0, :]  # (batch, d_model)\n",
        "\n",
        "        # Classification\n",
        "        output = self.fc(cls_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Create transformer model\n",
        "transformer_model = TransformerClassifier().to(device)\n",
        "print(transformer_model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in transformer_model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6bzhOzss4mU"
      },
      "outputs": [],
      "source": [
        "# Train Transformer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(transformer_model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "print(\"Training Transformer...\\n\")\n",
        "transformer_history = train_model(\n",
        "    transformer_model, train_loader_seq, val_loader_seq, criterion, optimizer,\n",
        "    num_epochs=30, device=device, scheduler=scheduler, early_stopping=early_stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDrLKQoBs4mU"
      },
      "outputs": [],
      "source": [
        "plot_training_history(transformer_history, \"Transformer Training History\")\n",
        "\n",
        "test_loss, test_acc, _, _ = evaluate(transformer_model, test_loader_seq, criterion, device)\n",
        "print(f\"\\nTest Results: Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZLiby8Ls4mU"
      },
      "source": [
        "---\n",
        "<a name=\"part8\"></a>\n",
        "# Part 8: Comprehensive Comparison\n",
        "\n",
        "## 8.1 Architecture Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQIQhkyhs4mU"
      },
      "outputs": [],
      "source": [
        "# Compare all sequence models\n",
        "models_comparison = {\n",
        "    'Simple RNN': (rnn_model, rnn_history),\n",
        "    'LSTM': (lstm_model, lstm_history),\n",
        "    'GRU': (gru_model, gru_history),\n",
        "    'LSTM + Attention': (lstm_attn_model, lstm_attn_history),\n",
        "    'Transformer': (transformer_model, transformer_history),\n",
        "}\n",
        "\n",
        "# Create comparison table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ARCHITECTURE COMPARISON - SEQUENCE CLASSIFICATION\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Model':<20} {'Parameters':>12} {'Test Acc':>12} {'Best Val Acc':>14} {'Epochs':>8}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "results = []\n",
        "for name, (model, history) in models_comparison.items():\n",
        "    params = sum(p.numel() for p in model.parameters())\n",
        "    test_loss, test_acc, _, _ = evaluate(model, test_loader_seq, criterion, device)\n",
        "    best_val_acc = max(history['val_acc'])\n",
        "    epochs = len(history['val_acc'])\n",
        "\n",
        "    print(f\"{name:<20} {params:>12,} {test_acc:>11.2f}% {best_val_acc:>13.2f}% {epochs:>8}\")\n",
        "    results.append({'Model': name, 'Params': params, 'Test Acc': test_acc, 'Best Val Acc': best_val_acc})\n",
        "\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p084jipgs4mU"
      },
      "outputs": [],
      "source": [
        "# Visual comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Training loss comparison\n",
        "ax1 = axes[0, 0]\n",
        "for name, (model, history) in models_comparison.items():\n",
        "    ax1.plot(history['train_loss'], label=name, alpha=0.8)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Training Loss')\n",
        "ax1.set_title('Training Loss Comparison')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation loss comparison\n",
        "ax2 = axes[0, 1]\n",
        "for name, (model, history) in models_comparison.items():\n",
        "    ax2.plot(history['val_loss'], label=name, alpha=0.8)\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Validation Loss')\n",
        "ax2.set_title('Validation Loss Comparison')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation accuracy comparison\n",
        "ax3 = axes[1, 0]\n",
        "for name, (model, history) in models_comparison.items():\n",
        "    ax3.plot(history['val_acc'], label=name, alpha=0.8)\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Validation Accuracy (%)')\n",
        "ax3.set_title('Validation Accuracy Comparison')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Parameters vs Performance\n",
        "ax4 = axes[1, 1]\n",
        "for r in results:\n",
        "    ax4.scatter(r['Params'], r['Test Acc'], s=100, label=r['Model'])\n",
        "ax4.set_xlabel('Number of Parameters')\n",
        "ax4.set_ylabel('Test Accuracy (%)')\n",
        "ax4.set_title('Parameters vs Performance')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u55Fv7W5s4mV"
      },
      "source": [
        "## 8.2 Summary Table: When to Use Each Architecture\n",
        "\n",
        "| Architecture | Best For | Pros | Cons |\n",
        "|-------------|----------|------|------|\n",
        "| **ANN (MLP)** | Tabular data, simple classification | Simple, fast, easy to interpret | Can't handle spatial/temporal patterns |\n",
        "| **CNN** | Images, spatial data | Translation invariant, parameter efficient | Requires fixed input size, no temporal modeling |\n",
        "| **RNN** | Simple sequences | Handles variable-length inputs | Vanishing gradients, slow training |\n",
        "| **LSTM** | Long sequences, time series | Captures long-range dependencies | More parameters, slower than GRU |\n",
        "| **GRU** | Similar to LSTM | Fewer parameters, faster | Slightly less powerful than LSTM |\n",
        "| **Transformer** | NLP, complex sequences | Parallelizable, captures long-range deps | Quadratic memory in sequence length |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWD0Qtbys4mV"
      },
      "source": [
        "---\n",
        "<a name=\"part9\"></a>\n",
        "# Part 9: Final Project\n",
        "\n",
        "## Project: Build Your Own Deep Learning Pipeline\n",
        "\n",
        "### Requirements\n",
        "\n",
        "Choose ONE of the following projects:\n",
        "\n",
        "#### Option A: Image Classification with CNN\n",
        "- Use the CIFAR-10 dataset\n",
        "- Implement a CNN with at least 3 convolutional layers\n",
        "- Include batch normalization and dropout\n",
        "- Implement data augmentation\n",
        "- Achieve at least 80% test accuracy\n",
        "\n",
        "#### Option B: Sequence Prediction with LSTM/Transformer\n",
        "- Generate or use a time series dataset\n",
        "- Implement both LSTM and Transformer models\n",
        "- Compare their performance\n",
        "- Visualize attention weights\n",
        "\n",
        "#### Option C: Text Classification\n",
        "- Use a text classification dataset (e.g., IMDB reviews)\n",
        "- Implement word embeddings\n",
        "- Build both RNN-based and Transformer-based classifiers\n",
        "- Compare and analyze results\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "1. **Code**: Well-documented implementation\n",
        "2. **Analysis**:\n",
        "   - Architecture description and justification\n",
        "   - Training curves and metrics\n",
        "   - Comparison with baseline\n",
        "3. **Discussion**:\n",
        "   - What worked well?\n",
        "   - What challenges did you face?\n",
        "   - How would you improve the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaWpFwPJs4mV"
      },
      "outputs": [],
      "source": [
        "# YOUR FINAL PROJECT CODE HERE\n",
        "\n",
        "# Example structure:\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "# ...\n",
        "\n",
        "# 2. Define model architecture\n",
        "# ...\n",
        "\n",
        "# 3. Training loop\n",
        "# ...\n",
        "\n",
        "# 4. Evaluation and visualization\n",
        "# ...\n",
        "\n",
        "# 5. Analysis and conclusions\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Dbvgpcs4mV"
      },
      "source": [
        "## 9.2 Saving and Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1L8msGdms4mV"
      },
      "outputs": [],
      "source": [
        "# Save a model\n",
        "def save_model(model, optimizer, epoch, path='model_checkpoint.pth'):\n",
        "    \"\"\"Save model checkpoint.\"\"\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, path)\n",
        "    print(f\"Model saved to {path}\")\n",
        "\n",
        "# Load a model\n",
        "def load_model(model, optimizer, path='model_checkpoint.pth'):\n",
        "    \"\"\"Load model checkpoint.\"\"\"\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    print(f\"Model loaded from {path} (epoch {epoch})\")\n",
        "    return model, optimizer, epoch\n",
        "\n",
        "# Example usage\n",
        "# save_model(transformer_model, optimizer, epoch=30, path='transformer_checkpoint.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-gKriaos4mV"
      },
      "source": [
        "---\n",
        "\n",
        "# üìã Assignment Checklist\n",
        "\n",
        "Before submitting, ensure you have completed:\n",
        "\n",
        "- [ ] **Part 1**: Answered Exercise 1.1 (Activation Functions)\n",
        "- [ ] **Part 2**: Completed Exercise 2.1 (Modified ANN)\n",
        "- [ ] **Part 3**: Completed Exercise 3.1 (CNN Feature Maps)\n",
        "- [ ] **Part 4**: Completed Exercise 4.1 (Bidirectional RNN)\n",
        "- [ ] **Part 5**: Completed Exercise 5.1 (LSTM vs GRU Analysis)\n",
        "- [ ] **Part 9**: Final Project with all deliverables\n",
        "\n",
        "### Grading Rubric\n",
        "\n",
        "| Component | Points |\n",
        "|-----------|--------|\n",
        "| Exercises (1.1 - 5.1) | 4 |\n",
        "| Final Project Implementation | 3 |\n",
        "| Final Project Analysis | 2 |\n",
        "| Code Quality & Documentation | 1 |\n",
        "| **Total** | **10** |\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Additional Resources\n",
        "\n",
        "- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n",
        "- [Deep Learning Book by Goodfellow et al.](https://www.deeplearningbook.org/)\n",
        "- [Attention Is All You Need (Transformer Paper)](https://arxiv.org/abs/1706.03762)\n",
        "- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck with your assignment!** üöÄ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
